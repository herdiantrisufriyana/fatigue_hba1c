---
title: "Large language model-assisted causal machine learning for identifying fatigue-related poor glycated hemoglobin in type 2 diabetes"
author:
  - name: Herdiantri Sufriyana
    affiliation:
    - &nycu Institute of Biomedical Informatics, College of Medicine, National 
      Yang Ming Chiao Tung University, Taipei, Taiwan.
    email: herdi@nycu.edu.tw
  - name: Debby Syahru Romadlon
    affiliation:
    - &cu Faculty of Nursing, Chulalongkorn University, Bangkok, Thailand.
  - name: Rudy Kurniawan
    affiliation:
    - &chula Diabetes Connection Care, Eka Hospital Bumi Serpong Damai, 
      Tangerang, Indonesia.
  - name: Safiruddin Al Baqi
    affiliation:
    - &siip Faculty of Education and Teaching Sciences, State Islamic 
      Institute of Ponorogo, Ponorogo, Indonesia.
  - name: Emmanuel Ekpor
    affiliation:
    - &ug School of Nursing, University of Ghana, Legon, Ghana.
  - name: Eric Peprah Osei
    affiliation:
    - &uic College of Nursing, University of Illinois Chicago, Illinois, 
      United States.
  - name: Hsiao-Yean Chiu
    affiliation:
    - &tmu School of Nursing, College of Nursing, Taipei Medical University, 
      Taipei, Taiwan.
    - &tmu2 Research Center of Sleep Medicine, College of Medicine, 
      Taipei Medical University, Taipei, Taiwan.
    - &tmuh Department of Nursing, Taipei Medical University Hospital, Taipei, 
      Taiwan.
  - name: Emily Chia-Yu Su
    affiliation:
    - *nycu
    - &tmu3 Graduate Institute of Biomedical Informatics, College of Medical 
      Science and Technology, Taipei Medical University, Taipei, Taiwan.
    - &tmuh2 Clinical Big Data Research Center, Taipei Medical University 
      Hospital, Taipei, Taiwan.
date: "2024-08-09"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
vignette: >
  %\VignetteIndexEntry{Large language model-assisted causal machine learning for identifying fatigue-related poor glycated hemoglobin in type 2 diabetes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Programming environment

```{r Set random seed, include=FALSE}
seed=2024-08-09
```

```{r Load packages, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggpubr)
library(broom)
library(MASS)
select <- dplyr::select
library(igraph)
library(ggnetwork)
library(brms)
library(broom.mixed)
library(pbapply)
library(mice)
filter <- dplyr::filter
cbind <- base::cbind
rbind <- base::rbind
```

```{r Choose theme, include=FALSE}
dslabs::ds_theme_set()
```

```{r Determine kable format, include=FALSE}
kable_format <- 'html'
```

```{r Load functions, include=FALSE}
list.files('R/',full.names=T) |>
  lapply(source)
```

# Data preprocessing

```{r Download raw data, eval=FALSE, include=FALSE}
download.file(
  "https://zenodo.org/records/14848167/files/raw_data3.sav?download=1"
  , destfile = "inst/extdata/raw_data3.sav"
)
```

```{r Load raw data, include=FALSE}
raw_data <- haven::read_sav("inst/extdata/raw_data3.sav")
```

```{r Write old column names, eval=FALSE, include=FALSE}
raw_data |>
  colnames() |>
  as.data.frame() |>
  `colnames<-`("old_colname") |>
  write_csv("inst/extdata/old_colname.csv")
```

```{r Read new column names, include=FALSE}
new_colname <-
  read_csv("inst/extdata/new_colname.csv", show_col_types = FALSE)
```

```{r table-1, echo=FALSE}
new_colname |>
  kable(
    format = kable_format
    ,caption = "Table 1. Column name conversion."
  ) |>
  kable_classic()
```

```{r Standardize column names, include=FALSE}
cleaned_data1 <-
  raw_data |>
  `colnames<-`(
    data.frame(old_colname = colnames(raw_data)) |>
      left_join(new_colname,by = join_by(old_colname)) |>
      pull(new_colname)
  )
```

```{r Write old predefined labels, eval=FALSE, include=FALSE}
cleaned_data1 |>
  lapply(attr, "label") |>
  imap(~ data.frame(value = .x)) |>
  lapply(rownames_to_column, var = "old_label") |>
  imap(~ mutate(.x, variable = .y)) |>
  reduce(rbind) |>
  select(variable, value, everything()) |>
  write_csv("inst/extdata/old_predefined_label.csv")
```

```{r Read new existing labels, include=FALSE}
new_existing_label <-
  read_csv("inst/extdata/new_predefined_label.csv", show_col_types = FALSE)
```

```{r table-2, echo=FALSE}
new_existing_label |>
  kable(
    format = kable_format
    ,caption = "Table 2. Predefined label conversion."
  ) |>
  kable_classic()
```

```{r Use new existing labels as values if any, include=FALSE}
cleaned_data2 <-
  cleaned_data1 |>
  select_at(unique(new_existing_label$variable)) |>
  mutate_all(as.character) |>
  mutate(i = seq(n())) |>
  gather(variable, value, -i) |>
  left_join(
    mutate_all(new_existing_label, as.character)  
    ,by = join_by(variable, value)
  ) |>
  select(i, variable, value = new_label) |>
  spread(variable, value) |>
  arrange(i) |>
  select(-i)

cleaned_data2 <-
  cleaned_data2 |>
  cbind(
    cleaned_data1 |>
      select_at(
        colnames(cleaned_data1)[
          !colnames(cleaned_data1)
          %in% colnames(cleaned_data2)
        ]
      )
  )

cleaned_data2 <-
  cleaned_data2 |>
  select_at(colnames(cleaned_data1))
```

```{r Determine identifiers, include=FALSE}
cleaned_data3 <-
  cleaned_data2 |>
  mutate(
    id_no =
      str_pad(
        id_no
        ,str_count(max(id_no))
        ,"left"
        ,0
      )
    ,id_init=
      str_to_lower(id_init)
  ) |>
  unite(id, id_no, id_init, sep = "_") |>
  column_to_rownames(var = "id")
```

```{r Finalize cleaned data without SPSS attributes, include=FALSE}
cleaned_data <-
  cleaned_data3 |>
  lapply(`attributes<-`,NULL) |>
  as.data.frame() |>
  `rownames<-`(rownames(cleaned_data3))
```

# Data transformation

```{r Separate categorical and numerical variables, include=FALSE}
cat_data <-
  cleaned_data |>
  select_if(!sapply(cleaned_data, is.numeric))

num_data <-
  cleaned_data |>
  select_if(sapply(cleaned_data, is.numeric))
```

```{r Normal QQ plots of numeric variables, include=FALSE}
normal_qq <-
  num_data |>
  imap(
    ~ data.frame(value = .x) |>
      ggplot(aes(sample = value)) +
      stat_qq(na.rm = TRUE) +
      stat_qq_line(color = "red", na.rm = TRUE) +
      coord_flip() +
      xlab("Normal Quantiles") +
      ylab(.y)
  )

normal_qq <-
  normal_qq |>
  length() |>
  seq() |>
  split(LETTERS[1:3]) |>
  data.frame() |>
  pmap(
    \(A, B, C)
    ggarrange(
      normal_qq[[A]]
      ,normal_qq[[B]]
      ,normal_qq[[C]]
      ,ncol = 3
    )
  )

normal_qq <-
  ggarrange(
    normal_qq[[1]]
    ,ncol=1
  )
```

```{r figure-1, echo=FALSE, fig.height=5, fig.width=15}
normal_qq
```

```{r Determine normality by QQ plot, include=FALSE}
var_num_normal_qq <- c('age', 'dm_duration')
```

```{r Numerical variables with normal distribution by QQ plots, echo=FALSE}
var_num_normal_qq |>
  paste0(collapse=', ') |>
  cat()
```

```{r Normality test of numerical variables, include=FALSE}
normal_test <-
  num_data |>
  select_if(!names(num_data) %in% var_num_normal_qq) |>
  lapply(shapiro.test) |>
  lapply(tidy) |>
  imap(~ mutate(.x, variable = .y)) |>
  lapply(select, variable, everything()) |>
  reduce(rbind)
```

```{r table-3, echo=FALSE}
normal_test |>
  select(-method) |>
  mutate_at("statistic", round, 3) |>
  arrange(p.value) |>
  mutate(variable = paste0(variable, ifelse(p.value<=0.05,"*",""))) |>
  mutate(p.value = ifelse(p.value<0.001, "<0.001", round(p.value,3))) |>
  kable(
    format = kable_format
    ,caption = "Table S2. Normality test."
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic()
```

```{r Determine num variables that are not normally distributed, include=FALSE}
var_num_non_normal=
  normal_test |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normally distributed, echo=FALSE}
var_num_non_normal |>
  paste0(collapse=', ') |>
  cat()
```

```{r Non-normal mumerical variables with 0, include=FALSE}
var_num_non_normal_with_zero <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x==0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables with <0, include=FALSE}
var_num_non_normal_with_neg <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(x<0)) |>
  which() |>
  names()
```

```{r Non-normal mumerical variables infinited exp, include=FALSE}
var_num_non_normal_with_inf_exp <-
  num_data |>
  select_at(var_num_non_normal) |>
  lapply(\(x) x[!duplicated(x)]) |>
  lapply(\(x) x[!is.na(x)]) |>
  sapply(\(x) any(is.infinite(exp(x)))) |>
  which() |>
  names()
```

```{r Determine choices for a transformation technique, include=FALSE}
trans_choice <-
  data.frame(variable = var_num_non_normal) |>
  mutate(
    log =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        ,0
        ,1
      )
    ,sqrt =
      ifelse(
        variable%in%var_num_non_normal_with_neg
        ,0
        ,1
      )
    ,inv =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        ,0
        ,1
      )
    ,log2 =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        ,0
        ,1
      )
    ,exp =
      ifelse(
        variable%in%var_num_non_normal_with_inf_exp
        ,0
        ,1
      )
    ,asinh = 1
    ,bct =
      ifelse(
        variable%in%var_num_non_normal_with_zero
        | variable%in%var_num_non_normal_with_neg
        ,0
        ,1
      )
  )
```

```{r Choices for a transformation technique, echo=FALSE}
trans_choice |>
  colnames() |>
  setdiff("variable") |>
  paste0(collapse=', ') |>
  cat()
```

```{r Simple transformations, include=FALSE}
simple_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(!func %in% c("bct"))

simple_trans <-
  simple_trans |>
  pull(func) |>
  unique() |>
  lapply(
    \(x)
    simple_trans |>
      filter(func == x) |>
      pull(variable) |>
      lapply(
        \(y)
        list(
            log = log
            ,sqrt = sqrt
            ,inv = \(x) 1/x
            ,log2 = log2
            ,exp = exp
            ,asinh = asinh
          )[[x]](num_data[[y]]) |>
          as.data.frame() |>
          `colnames<-`(y)
      )
  ) |>
  `names<-`(unique(simple_trans$func))
```

```{r Box-Cox transformation (BCT), include=FALSE}
bc_trans <-
  trans_choice |>
  gather(func, do, -variable) |>
  filter(do == 1) |>
  select(-do) |>
  filter(func %in% c("bct")) |>
  pull(variable)

bc_trans <-
  bc_trans |>
  `names<-`(as.character(bc_trans)) |>
  as.list()

for(i in names(bc_trans)){
  bc_trans[[i]]=
    boxcox(
      lm(num_data[[i]] ~ 1)
      ,lambda = seq(-2, 2, by = 0.1)
      ,plot = F
    ) |>
    c(list(value = num_data[[i]]))
}

rm(i)

bc_trans=
  bc_trans |>
  lapply(
    \(x)
    list(
      rep(NA, length(x$value))
      ,(x$value^(x$x[which.max(x$y)]) - 1) / x$x[which.max(x$y)]
    )[[ifelse(
        abs(x$x[which.max(x$y)]) < 1e-10
          ,1
          ,2
        )
    ]]
  ) |>
  imap(
    ~ data.frame(trans=.x) |>
      `colnames<-`(.y)
  )

bc_trans <-
  bc_trans[sapply(bc_trans, \(x) !all(is.na(x[[1]])))]
```

```{r Normality test of transformed numerical variables, include=FALSE}
normal_test_after_trans <-
  simple_trans |>
  c(list(bct = bc_trans)) |>
  imap(
    ~ .x[[1]] |>
      lapply(shapiro.test) |>
      lapply(tidy) |>
      imap(~ mutate(.x, variable = .y)) |>
      reduce(rbind) |>
      mutate(func = .y)
  ) |>
  reduce(rbind) |>
  select(func, variable, p.value) |>
  mutate_at("func", \(x) factor(x, unique(x))) |>
  group_by(variable) |>
  mutate(best_trans = func[which.max(p.value)]) |>
  ungroup() |>
  spread(func, p.value) |>
  right_join(
    data.frame(variable = var_num_non_normal)
    ,by = join_by(variable)
  ) |>
  mutate(
    p.value=
      ifelse(
        best_trans == "log"
        ,log
        ,ifelse(
          best_trans == "sqrt"
          ,sqrt
          ,ifelse(
            best_trans == "inv"
            ,inv
            ,ifelse(
              best_trans == "log2"
              ,log2
              ,ifelse(
                best_trans == "exp"
                ,exp
                ,ifelse(
                  best_trans == "asinh"
                  ,asinh
                  ,bct
                )
              )
            )
          )
        )
      )
  ) |>
  select(variable, best_trans, p.value, everything())
```

```{r table-4, echo=FALSE}
normal_test_after_trans |>
  mutate(variable = paste0(variable, ifelse(p.value <= 0.05, "*", ""))) |>
  arrange(p.value) |>
  mutate_if(is.numeric, \(x) ifelse(x < 0.001, "<0.001", round(x, 3))) |>
  mutate_if(is.numeric, as.character) |>
  kable(
    format = kable_format
    ,caption = "Table 4. Normality test after transformation."
  ) |>
  footnote("*, p-value <=0.05, Shapiro-Wilk normality test.") |>
  kable_classic()
```

```{r Determine num vars that are not normal after transformed, include=FALSE}
var_num_non_normal_after_trans <-
  normal_test_after_trans |>
  filter(p.value <= 0.05) |>
  pull(variable)
```

```{r Numerical variables that are not normal after transformation, echo=FALSE}
var_num_non_normal_after_trans |>
  paste0(collapse = ", ") |>
  cat()
```

```{r Write those are not normal after transformed, eval=FALSE, include=FALSE}
data.frame(variable = var_num_non_normal_after_trans) |>
  write_csv('inst/extdata/var_num_non_normal_after_trans.csv')
```

```{r Define cats for vars that are not normal after transformed, include=FALSE}
var_num_non_normal_after_trans_category <-
  read_csv(
    "inst/extdata/var_num_non_normal_after_trans_category.csv"
    ,show_col_types = FALSE
  )
```

```{r Cats for vars that are not normal after transformation, echo=FALSE}
var_num_non_normal_after_trans_category |>
  kable(
    format =  kable_format
    ,caption = 
      paste0(
        "Categorization for variables that "
        ,"are not normal after transformation."
      )
    ,
  ) |>
  footnote(
    paste0(
      "A category was defined if a value was "
      ,"less or equal to cutoff. "
      ,"HbA1c was floored at 1 decimal."
    )
  ) |>
  kable_classic()
```

```{r Transformation by categorization, include=FALSE}
cat_trans <-
  num_data |>
  select_at(var_num_non_normal_after_trans) |>
  mutate_at("hba1c", \(x) floor(x*10)/10) |>
  imap(
    ~ .x |>
      cut(
        breaks=
          c(-Inf
            ,var_num_non_normal_after_trans_category |>
              filter(variable == .y) |>
              pull(cutoff)
          )
        ,include.lowest = TRUE
        ,labels = FALSE
      ) |>
      as.data.frame() |>
      `colnames<-`("cat_num") |>
      left_join(
        var_num_non_normal_after_trans_category |>
          filter(variable == .y) |>
          pull(category) |>
          as.data.frame() |>
          `colnames<-`("cat_num") |>
          mutate_at("cat_num", \(x) factor(x, unique(x))) |>
          mutate(
            cat_name = cat_num
            ,cat_num = as.numeric(cat_num)
          )
        ,by = join_by(cat_num)
      ) |>
      pull(cat_name) |>
      as.data.frame() |>
      `colnames<-`(.y)
  ) |>
  reduce(cbind) |>
  `rownames<-`(rownames(num_data)) |>
  mutate_all(as.character) |>
  rename_all(paste0, "_trans")
```

```{r Finalize transformed data, include=FALSE}
transformed_data <-
  num_data |>
  cbind(cat_trans) |>
  cbind(cat_data) |>
  select_at(c(colnames(cat_trans), colnames(cleaned_data)))
```

# Outlier analysis

```{r Numerical var after transformation, include=FALSE}
trans_ps_num_data <-
  transformed_data |>
  select_if(sapply(transformed_data, is.numeric))

trans_ps_num_data <-
  trans_ps_num_data |>
  select_at(
    colnames(trans_ps_num_data) |>
      setdiff(var_num_non_normal_after_trans)
  )
```

```{r Identify outliers, include=FALSE}
outlier_data <-
  trans_ps_num_data |>
  rownames_to_column(var = "id") |>
  mutate_at("id", \(x) factor(x, unique(x))) |>
  gather(variable, value, -id) |>
  group_by(variable) |>
  mutate(
    q1 =
      value |>
      quantile(0.25, na.rm=T)
    ,q3 =
      value |>
      quantile(0.75, na.rm=T)
  ) |>
  ungroup() |>
  mutate(
    outlier =
      value < (q1 - 1.5 * (q3 - q1))
      | value > (q3 + 1.5 * (q3 - q1))
  )
```

```{r table-5, echo=FALSE}
outlier_data |>
  group_by(variable) |>
  summarize(p_outliers = mean(outlier, na.rm=T)) |>
  mutate(p_outliers = round(p_outliers * 100, 2)) |>
  arrange(desc(p_outliers)) |>
  kable(
    format = kable_format
    ,caption = "Outlier proportions of numerical variables."
  ) |>
  kable_classic()
```

```{r Assign outliers to missing, include=FALSE}
outlier_removed_data <-
  outlier_data |>
  mutate(value = ifelse(outlier, NA, value)) |>
  select(id, variable, value) |>
  spread(variable,value) |>
  arrange(id) |>
  column_to_rownames(var = "id") |>
  cbind(transformed_data[!sapply(transformed_data, is.numeric)]) |>
  cbind(
    transformed_data[
      colnames(transformed_data)
      %in% var_num_non_normal_after_trans
    ]
  )

outlier_removed_data <-
  outlier_removed_data[colnames(transformed_data)]
```

# Correlation matrix

```{r Identify and create missingness variables, include=FALSE}
ms_added_data <-
  outlier_removed_data |>
  sapply(\(x) any(is.na(x))) |>
  which() |>
  names() |>
  lapply(
    \(x)
    outlier_removed_data |>
      select_at(x) |>
      `colnames<-`("value") |>
      mutate(value = ifelse(is.na(value), "yes", "no")) |>
      `colnames<-`(paste0("ms_", x))
  ) |>
  reduce(cbind) |>
  cbind(outlier_removed_data)
```

```{r Write complete column names, eval=FALSE, include=FALSE}
ms_added_data |>
  colnames() |>
  as.data.frame() |>
  `colnames<-`("colname") |>
  write_csv("inst/extdata/colname.csv")
```

```{r Read labels of complete column names, include=FALSE}
colname_label <-
  read_csv("inst/extdata/colname_label.csv", show_col_types = FALSE)
```

```{r Check categorical variables with a category of 1 value, include=FALSE}
var_cat_val1=
  ms_added_data |>
  select_if(!sapply(ms_added_data, is.numeric)) |>
  gather(variable, value) |>
  group_by_all() |>
  summarize(n = n(), .groups = "drop") |>
  filter(n <= 1) |>
  pull(variable) |>
  unique()
```

```{r Categorical variables with a category of 1 value, echo=FALSE}
var_cat_val1 %>%
  paste0(collapse=', ') %>%
  cat()
```

```{r Pair-wise distribution of categorical variables, include=FALSE}
pairwise_cat_sum <-
  ms_added_data |>
  select_if(
    !sapply(ms_added_data, is.numeric)
    & !colnames(ms_added_data) %in% var_cat_val1
  ) |>
  colnames() |>
  combn(2) |>
  as.data.frame() |>
  lapply(
    \(x)
    ms_added_data |>
      select_at(x) |>
      group_by_all() |>
      summarize(n = n(), .groups = "drop") |>
      select_at(c(x, "n")) |>
      `colnames<-`(c("V1_value", "V2_value", "n")) |>
      mutate(V1 = x[1], V2 = x[2])
  ) |>
  lapply(
    \(x)
    expand.grid(
      V1_value = unique(x$V1_value)
      ,V2_value = unique(x$V2_value)
      ) |>
      mutate_all(as.character) |>
      left_join(x, by = join_by(V1_value, V2_value)) |>
      mutate_at("n", \(x) ifelse(is.na(x), 0, x)) |>
      fill(V1, V2)
  ) |>
  reduce(rbind) |>
  select(V1, V1_value, V2, V2_value, everything())
```

```{r Pair-wise perfect separation, include=FALSE}
pairwise_cat_sum_ps <-
  pairwise_cat_sum |>
  group_by(V1, V2) |>
  summarize(ps = any(n == 0), .groups = "drop")
```

```{r table-6, echo=FALSE}
pairwise_cat_sum |>
  inner_join(
    pairwise_cat_sum_ps |>
      filter(ps) |>
      select(-ps)
    ,by = join_by(V1, V2)
  ) |>
  filter(n == 0) |>
  kable(
    format = kable_format
    ,caption =
      paste0(
        "Table 6. Categorical variables with "
        ,"pair-wise perfect separation."
      )
  ) |>
  kable_classic()
```

```{r Conduct corr tests for each pair with PS, eval=FALSE, include=FALSE}
correlation_matrix_ps <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(
    paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  pmap(\(V1, V2) list(V1 = V1, V2 = V2)) |>
  pblapply(
    \(x)
    suppressWarnings(auto_stat_tests(
        ms_added_data[[x$V1]]
        ,ms_added_data[[x$V2]]
        ,perfect_separation = TRUE
      )) |>
      list() |>
      `names<-`("obj") |>
      c(list(V1 = x$V1, V2 = x$V2))
  ) |>
  lapply(
    \(x)
    suppressWarnings(tidy(x$obj)) |>
      filter(!str_detect(term, "\\(Intercept\\)")) |>
      filter(!(conf.low <= 0 & conf.high >= 0)) |>
      summarize(n_sig = n()) |>
      mutate(p.value = ifelse(n_sig > 0, 0, 1)) |>
      filter(!is.na(p.value)) |>
      select(p.value) |>
      mutate(
        V1 = x$V1
        ,V2 = x$V2
      )
  ) |>
  reduce(rbind)

saveRDS(correlation_matrix_ps, "data/correlation_matrix_ps.rds")
```

```{r Load pre-conduct corr tests for each pair with PS, include=FALSE}
correlation_matrix_ps <- readRDS("data/correlation_matrix_ps.rds")
```

```{r Conduct correlation tests for each pair without PS, include=FALSE}
correlation_matrix_non_ps <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  pmap(
    \(V1, V2)
    suppressWarnings(auto_stat_tests(
        ms_added_data[[V1]]
        ,ms_added_data[[V2]]
        ,normal_V1 = !V1 %in% var_num_non_normal_after_trans
        ,normal_V2 = !V2 %in% var_num_non_normal_after_trans
      )) |>
      tidy() |>
      filter(!is.na(p.value)) |>
      select(p.value) |>
      mutate(
        V1 = V1
        ,V2 = V2
      )
  ) |>
  reduce(rbind)
```

```{r Conduct correlation tests for each pair, include=FALSE}
correlation_matrix <-
  correlation_matrix_ps |>
  rbind(correlation_matrix_non_ps) |>
  mutate(p.value = p.adjust(p.value, "BH")) |>
  rename(cor.p.value = p.value) |>
  right_join(
    ms_added_data |>
      colnames() |>
      combn(2) |>
      as.data.frame() |>
      t() |>
      as.data.frame() |>
      `rownames<-`(NULL)
    ,by = join_by(V1, V2)
  ) |>
  mutate(
    V1 = factor(V1, colnames(ms_added_data))
    ,V2 = factor(V2, levels(V1))
  ) |>
  arrange(V1, V2)
```

```{r Obtain correlation test names for each pair with PS, include=FALSE}
correlation_test_names_ps <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(
    paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  pmap(\(V1, V2) list(V1 = V1, V2 = V2)) |>
  lapply(
    \(x)
    suppressWarnings(auto_stat_test_names(
        ms_added_data[[x$V1]]
        ,ms_added_data[[x$V2]]
        ,perfect_separation = TRUE
      )) |>
      list() |>
      `names<-`("test") |>
      c(list(V1 = x$V1, V2 = x$V2))
  ) |>
  lapply(as.data.frame) |>
  reduce(rbind)
```

```{r Obtain correlation test names for each pair without PS, include=FALSE}
correlation_test_names_non_ps <-
  ms_added_data |>
  colnames() |>
  setdiff(var_cat_val1) |>
  combn(2) |>
  as.data.frame() |>
  t() |>
  as.data.frame() |>
  `rownames<-`(NULL) |>
  filter(
    !paste0(V1, V2)
    %in% c(
      pairwise_cat_sum_ps |>
        filter(ps) |>
        unite(V1V2, V1, V2, sep = "") |>
        pull(V1V2)
    )
  ) |>
  filter(str_remove_all(V1, "^ms_") != str_remove_all(V2, "^ms_")) |>
  pmap(
    \(V1, V2)
    suppressWarnings(auto_stat_test_names(
        ms_added_data[[V1]]
        ,ms_added_data[[V2]]
        ,normal_V1 = !V1 %in% var_num_non_normal_after_trans
        ,normal_V2 = !V2 %in% var_num_non_normal_after_trans
      )) |>
      list() |>
      `names<-`("test") |>
      c(list(V1 = V1, V2 = V2))
  ) |>
  lapply(as.data.frame) |>
  reduce(rbind)
```

```{r Obtain correlation test names for each pair, include=FALSE}
correlation_test_names <-
  correlation_test_names_ps |>
  rbind(correlation_test_names_non_ps) |>
  mutate(
    V1 = factor(V1, colnames(ms_added_data))
    ,V2 = factor(V2, levels(V1))
  ) |>
  arrange(V1, V2)
```

```{r figure-2, echo=FALSE, fig.height=5, fig.width=7}
same_v_corr_df =
  data.frame(
    cor.p.value = 0
    ,V1 = colnames(ms_added_data)
    ,V2 = colnames(ms_added_data)
    ,sig = "2 - Significant"
  )

correlation_matrix |>
  mutate(
    V1 = factor(V1, rev(levels(V1)))
    ,sig =
      ifelse(
        is.na(cor.p.value)
        ,ifelse(
          str_remove_all(V1, "^ms_") == str_remove_all(V2, "^ms_")
          ,"3 - Not tested†"
          ,ifelse(
            V1 %in% var_cat_val1
            | V2 %in% var_cat_val1
            ,"4 - Not tested‡"
            ,"5 - Not tested§"
          )
        )
        ,ifelse(cor.p.value <= 0.05, "2 - Significant", "1 - Not significant")
      ) |>
      factor()
    ,sig = factor(sig)
    ,cor.p.value = ifelse(cor.p.value<0.001, "<0.001", round(cor.p.value,3))
  ) |>
  rbind(same_v_corr_df) |>
  left_join(
    correlation_test_names |>
      left_join(
        select(correlation_test_names, test) |>
          unique() |>
          mutate(test_n = seq(n()))
        # |>
        #   unite(test, test_n, test, sep = ") ") |>
        #   pull(test) |>
        #   paste0(collapse = "; (") |>
        #   cat()
        , by = join_by(test)
      )
    , by = join_by(V1, V2)
  ) |>
  ggplot(aes(V1, V2, fill = sig)) +
  geom_tile(color = "white", na.rm = TRUE) +
  geom_text(aes(label = test_n), size = 2.5, na.rm = TRUE) +
  geom_tile(data = same_v_corr_df, fill = "white") +
  geom_text(
    data =
      same_v_corr_df |>
      left_join(rename(colname_label, V1 = colname), by = join_by(V1))
    ,aes(label = label)
    ,size = 2.5
    ,angle = 70
    ,hjust = 1
    ,nudge_x = 0.3
    ,nudge_y = 0.3
  ) +
  coord_flip() +
  xlab("") +
  ylab("") +
  scale_fill_discrete("Significance*") +
  theme(
    panel.grid = element_blank()
    ,panel.border = element_blank()
    ,axis.ticks = element_blank()
    ,axis.text = element_blank()
  )
```

Figure 2. Correlation matrix. The numbers indicate the statistical tests: (1) Bayesian binomial logistic regression analysis; (2) Fisher's exact test; (3) Welch's t-test; (4) Mann-Whitney U Test (Wilcoxon Rank-Sum Test); (5) Analysis of variance (ANOVA); (6) Pearson's correlation test; (7) Spearman's correlation test; (8) Bayesian multinomial logistic regression analysis; and (9) Kruskal-Wallis test. *, based on p-value (frequentist) or 95% CI (Bayesian); †, pair of variable and its missingness; ‡, at least 1 variable was a categorical variable with a category of 1 value.


```{r Write pairs with significant correlations, eval=FALSE, include=FALSE}
correlation_matrix |>
  filter(cor.p.value <= 0.05) |>
  filter(
    !(V1 %in% paste0(var_num_non_normal, "_trans")
      | V2 %in% paste0(var_num_non_normal, "_trans")
    )
  ) |>
  select(V1, V2) |>
  write_csv("inst/extdata/correlation.csv")
```

# Correlation direction

```{r Prompt template to identify corr direction, include=FALSE}
correlation_direction_prompt_template <-
  read_csv(
    "inst/extdata/correlation_direction_prompt_template.csv"
    ,show_col_types = FALSE
  )
```

```{r Write variables to be defined, eval=FALSE, include=FALSE}
correlation_matrix |>
  filter(
    !(V1 %in% paste0(var_num_non_normal, "_trans")
      | V2 %in% paste0(var_num_non_normal, "_trans")
    )
  ) |>
  select(V1, V2) |>
  gather() |>
  select(variable = value) |>
  unique() |>
  arrange(variable) |>
  write_csv("inst/extdata/variable_undefined.csv")
```

```{r Define variables, include=FALSE}
variable_definition <-
  read_csv(
    "inst/extdata/variable_defined.csv"
    ,show_col_types = FALSE
  )
```

```{r table-7, echo=FALSE}
correlation_matrix |>
  filter(!(str_detect(V1, "^ms_") | str_detect(V2, "^ms_"))) |>
  filter(
    !(V1 %in% paste0(var_num_non_normal, "_trans")
      | V2 %in% paste0(var_num_non_normal, "_trans")
    )
  ) |>
  filter(cor.p.value <= 0.05) |>
  select(V1, V2) |>
  left_join(
    variable_definition |>
      rename(V1 = variable, V1_definition = definition)
    ,by = join_by(V1)
  ) |>
  left_join(
    variable_definition |>
      rename(V2 = variable, V2_definition = definition)
    ,by = join_by(V2)
  ) |>
  t() |>
  as.data.frame() |>
  imap(
    ~ correlation_direction_prompt_template |>
      mutate_all(str_replace_all, "\\<Var1\\>Variable 1\\</Var1\\>", .x[1]) |>
      mutate_all(str_replace_all, "\\<Var2\\>Variable 2\\</Var2\\>", .x[2]) |>
      mutate_all(
        str_replace_all
        ,"\\<Definition1\\>Definition 1\\</Definition1\\>"
        ,.x[3]
      ) |>
      mutate_all(
        str_replace_all
        ,"\\<Definition2\\>Definition 2\\</Definition2\\>"
        ,.x[4]
      ) |>
      mutate(
        V1 = .x[1]
        ,V2 = .x[2]
      ) |>
      select(V1, V2, everything())
  ) |>
  reduce(rbind) |>
  mutate_at(c("V1", "V2"), \(x) factor(x, unique(x))) |>
  mutate_at("type", map_chr, ~ paste0("prompt_", .x)) |>
  spread(type, prompt) |>
  mutate_all(str_replace_all, "\\\\n", "<br>") |>
  kable(
    format = kable_format
    ,escape = FALSE
    ,caption =
      paste0(
        "Table 7. Prompts to identify "
        ,"hypothetical directions of the correlations."
      )
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align: top;")
```

```{r LLM responses of hypothetical direction of correlation, include=FALSE}
correlation_direction_response <-
  # 2024-08-16
  read_csv(
    "inst/extdata/correlation_direction_response.csv"
    ,show_col_types = FALSE
  ) |>
  
  # 2024-08-26
  rbind(
    read_csv(
      "inst/extdata/correlation_direction_response2.csv"
      ,show_col_types = FALSE
    )
  )
```

```{r table-8, echo=FALSE}
correlation_direction_response |>
  left_join(rename(colname_label, V1 = colname), by = join_by(V1)) |>
  mutate(V1 = label) |>
  select(-label) |>
  left_join(rename(colname_label, V2 = colname), by = join_by(V2)) |>
  mutate(V2 = label) |>
  select(-label) |>
  mutate(response = str_remove_all(response, "\\*\\*")) |>
  mutate(response = str_remove_all(response, "#")) |>
  rename(variable_1 = V1, variable_2 = V2) |>
  rename_all(str_replace_all, "_", " ") |>
  rename_all(str_to_sentence) |>
  kable(
    format = kable_format
    ,caption =
      paste0(
        "Table 8. ChatGPT response using GPT-4 backend to identify "
        ,"hypothetical directions of the correlations."
      )
  ) |>
  kable_classic() |>
  column_spec(1:3, extra_css = "vertical-align: top;")
```

```{r Determine hypothetical direction of correlation, include=FALSE}
correlation_direction <-
  correlation_direction_response |>
  mutate(
    answer =
      response |>
      lapply(\(x) str_split(x, "\n\n")[[1]]) |>
      lapply(\(x) x[length(x)]) |>
      lapply(\(x) paste0(str_extract_all(x, "[ABC][:graph:]*$")[[1]])) |>
      lapply(paste0, collapse = " - ") |>
      lapply(\(x) paste0(str_extract_all(x, "[ABC]")[[1]])) |>
      sapply(unique)
  ) |>
  mutate(
    direction =
      case_when(
        answer == "A" ~ "->"
        ,answer == "B" ~ "<-"
        ,answer == "C" ~ "-o-"
      )
  ) |>
  select(V1, V2, answer, direction)
```

```{r Create graph data frame based on hypothetical direction, include=FALSE}
correlation_graph_df <-
  correlation_direction |>
  mutate(
    from = ifelse(direction == "->", V1, V2)
    ,to = ifelse(direction == "->", V2, V1)
  ) |>
  select(from, to)
```

```{r Create graph plot based on hypothetical direction, include=FALSE}
correlation_graph_plot <-
  correlation_graph_df |>
  graph_from_data_frame() |>
  ggnetwork(
    layout=
      layout_as_tree(
        graph_from_data_frame(correlation_graph_df)
        ,root = c()
        ,mode = "in"
        ,circular = TRUE
      )
    ,arrow.gap = 0.075
  ) |>
  left_join(rename(colname_label, name = colname), by = join_by(name)) |>
  mutate(name = label) |>
  select(-label)

correlation_graph_plot <-
  correlation_graph_plot |>
  ggplot(aes(x, y, xend = xend, yend = yend, color = name, fill = name)) +
  geom_edges(
    arrow = arrow(length = unit(4, "pt"), type="closed")
    ,curvature = 0.1
    ,linewidth = 0.5
    ,show.legend = FALSE
  ) +
  geom_nodelabel(
    aes(label = name)
    ,color = "white"
    ,size = 2
    ,show.legend = FALSE
  ) +
  scale_x_continuous(
    limits =
      c(min(correlation_graph_plot$x) - 0.05
        ,max(correlation_graph_plot$xend) + 0
      )
  ) +
  scale_y_continuous(
    limits =
      c(min(correlation_graph_plot$y) - 0
        ,max(correlation_graph_plot$yend) + 0
      )
  ) +
  theme_void()
```

```{r figure-3, echo=FALSE, fig.height=3.54331, fig.width=3.54331}
correlation_graph_plot
```

```{r Fig. 1, eval=FALSE, fig.height=3.54331, fig.width=3.54331, include=FALSE}
correlation_graph_plot
ggsave("doc/figure1.eps", height = 3.54331, width = 3.54331, units = "in")
```

# Missing value imputation

```{r Imputation predictor matrix, include=FALSE}
imp_predictor_matrix <-
  correlation_matrix |>
  filter(!is.na(cor.p.value)) |>
  mutate(imp_predictor = ifelse(cor.p.value <= 0.05, 1, 0)) |>
  select(V1, V2, imp_predictor) |>
  mutate_at(c("V1", "V2"), str_remove_all, "^ms_") |>
  unique() |>
  right_join(
    expand.grid(
      V1 = colnames(outlier_removed_data)
      ,V2 = colnames(outlier_removed_data)
      ,stringsAsFactors = FALSE
    )
    ,by = join_by(V1, V2)
  ) |>
  mutate(imp_predictor = ifelse(V1 == V2, 0, imp_predictor)) |>
  pmap(
    \(V1, V2, imp_predictor)
    data.frame(
      V1_V2 =
        sort(c(V1, V2)) |>
        paste0(collapse = "|")
      ,imp_predictor = imp_predictor
    )
  ) |>
  reduce(rbind) |>
  separate(V1_V2, c("V1", "V2"), sep = "\\|") |>
  group_by(V1, V2) |>
  summarize(
    imp_predictor = as.integer(sum(imp_predictor, na.rm = TRUE) > 0)
    ,.groups = "drop"
  ) |>
  spread(V2, imp_predictor, fill = 0) |>
  column_to_rownames(var = "V1") |>
  as.matrix()

imp_predictor_matrix <-
  imp_predictor_matrix[
    colnames(outlier_removed_data)
    ,colnames(outlier_removed_data)
  ]
```

```{r Performing multiple imputation, include=FALSE}
imp_results <-
  suppressWarnings(
    mice(
      data = outlier_removed_data
      ,method = 'pmm'
      ,m = 10
      ,seed = seed
      ,predictorMatrix = imp_predictor_matrix
      ,print = FALSE
    )
  )
```

```{r Obtain imputed data, include=FALSE}
imputed_data <- complete(imp_results, 1)
```

# Descriptive statistics

```{r Finalize readily-analyzed data, include=FALSE}
processed_data <-
  imputed_data |>
  mutate_if(is.character, as.factor)
```

```{r Determine variables, include=FALSE}
var <- list()

var$dependent <- "fatigue"

var$independent <- c("hba1c", "hba1c_trans")

var$covariates=
  processed_data %>%
  colnames() %>%
  setdiff(unlist(var))
```

```{r Outcome-wise average and SD, include=FALSE}
avg_sd_data <-
  processed_data |>
  select_if(is.numeric) |>
  mutate(seq = seq(n())) |>
  gather(variable, value, -seq) |>
  left_join(
    processed_data |>
      select_at(var$dependent) |>
      mutate(seq = seq(n()))
    ,by = join_by(seq)
  ) |>
  group_by_at(c(var$dependent, "variable")) |>
  summarize(
    avg = mean(value)
    ,std = sd(value)
    ,.groups = 'drop'
  )
```

```{r Outcome-wise proportion, include=FALSE}
prop_n_data=
  processed_data |>
  select_at(reduce(var[!names(var) %in% "dependent"], c)) |>
  select_if(\(x) !is.numeric(x)) |>
  mutate_all(as.character) |>
  mutate(seq = seq(n())) |>
  gather(variable, value, -seq) |>
  left_join(
    processed_data |>
      select_at(var$dependent) |>
      mutate(seq=seq(n()))
    ,by = join_by(seq)
  ) |>
  select(-seq) |>
  group_by_at(c(var$dependent, "variable", "value")) |>
  summarize(n = n(), .groups='drop') |>
  group_by_at(c(var$dependent, "variable")) |>
  mutate(total = sum(n)) |>
  ungroup() |>
  mutate(p = round(n / total * 100, 0))
```

```{r table-9, echo=FALSE}
desc_stats <-
  list(
    avg_sd_data |>
      mutate_at(c("avg", "std"), round, 2) |>
      mutate(std = paste0("(", as.character(std), ")")) |>
      unite(avg_std, avg, std, sep=" ") |>
      mutate(value = NA) |>
      rename(summary = avg_std)
    ,prop_n_data |>
      select(-total) |>
      mutate(n = paste0("(", as.character(n), ")")) |>
      unite(p_n, p, n, sep = " ") |>
      rename(summary = p_n)
  ) |>
  lapply(rename_at, var$dependent, \(x) "dep_var") |>
  lapply(spread, dep_var, summary, fill = "0 (0)") |>
  reduce(rbind) |>
  mutate_at("value", as.character) |>
  mutate_at(
    "value"
    ,\(x)
    ifelse(
      is.na(x)
      , "average (SD)"
      , paste0(str_remove_all(x, "^[:digit:]+ - ")," % (n)")
    )
  ) |>
  mutate_at(
    "value"
    , \(x)
    str_replace_all(x, "oha", "OHA") |>
      str_replace_all("OHA_ins", "OHA + insulin")
  ) |>
  arrange(factor(variable, reduce(var[!names(var) %in% "dependent"], c))) |>
  left_join(
    rename(colname_label, variable = colname)
    , by = join_by(variable)
  ) |>
  mutate(variable = label) |>
  select(-label) |>
  mutate(variable = ifelse(duplicated(variable), "", variable))

desc_stats <-
  desc_stats |>
  `colnames<-`(
    data.frame(variable = colnames(desc_stats)) |>
      left_join(
        prop_n_data |>
          select_at(c(var$dependent, "total")) |>
          `colnames<-`(c("variable","total")) |>
          unique()
        ,by = join_by(variable)
      ) |>
      mutate_at("total", \(x) ifelse(is.na(x), "", paste0(" (n=", x, ")"))) |>
      unite(variable_total, variable, total, sep = "") |>
      pull(variable_total)
  )

desc_stats |>
  rename_at(
    3:4
    , str_replace_all
    , "^[:digit:]+"
    , colname_label$label[colname_label$colname == var$dependent]
  ) |>
  rename_all(str_to_sentence) |>
  rename_at("Value", \(x) " ") |>
  kable(
    format = kable_format
    ,caption = "Table 9. Sample characteristics."
  ) |>
  kable_classic()
```

# Univariate regression analysis

```{r Conduct univariate regression analysis, include=FALSE}
univar_reg <-
  processed_data |>
  colnames() |>
  setdiff(var$dependent)

univar_reg <-
  univar_reg |>
  `names<-`(univar_reg) |>
  lapply(c, var$dependent) |>
  lapply(rev) |>
  lapply(paste0, collapse='~') |>
  lapply(as.formula) |>
  lapply(glm, family = binomial(), data = processed_data) |>
  lapply(tidy) |>
  imap( ~ mutate(.x, variable = .y)) |>
  reduce(rbind) |>
  select(variable, everything()) |>
  mutate(
    term = str_remove_all(term, variable)
    ,term = ifelse(term == "", "value", term)
    ,OR = exp(estimate)
    ,LB = exp(estimate - qnorm(0.975) * std.error)
    ,UB = exp(estimate + qnorm(0.975) * std.error)
  )
```

```{r table-10, echo=FALSE}
univar_reg  |>
  filter(term != "(Intercept)") |>
  select_at(c("variable", "term", "OR", "LB", "UB", "p.value")) |>
  mutate_at(3:6, round, 1) |>
  filter(variable != "hba1c") |>
  filter(
    str_detect(
      variable
      , paste0(
          filter(correlation_graph_df, to == "fatigue")$from, collapse = "|"
        )
    )
  ) |>
  left_join(
    processed_data |>
      lapply(levels) |>
      imap(
        ~ data.frame(variable = .y, reference = ifelse(is.null(.x), NA, .x))
      ) |>
      reduce(rbind)
    , by = join_by(variable)
  ) |>
  left_join(
    rename(colname_label, variable = colname)
    , by = join_by(variable)
  ) |>
  mutate(variable = label) |>
  select(-label) |>
  mutate_at(
    c("term", "reference")
    ,\(x) str_remove_all(x, "^[:digit:]+ - ")
  ) |>
  mutate_at(
    c("term", "reference")
    , \(x)
    str_replace_all(x, "oha", "OHA") |>
      str_replace_all("OHA_ins", "OHA + insulin")
  ) |>
  unite(term_reference, term, reference, sep = " vs. ") |>
  mutate(variable = paste0(variable, ifelse(p.value <= 0.05, "*", ""))) |>
  mutate(
    p.value =
      ifelse(p.value < 0.001, "<0.001", round(p.value, 3)) |>
      as.character()
  ) |>
  unite(CI, LB, UB, sep = ", ") |>
  unite(CI_p, CI, p.value, sep = "; ") |>
  mutate(CI_p = paste0("(", CI_p, ")")) |>
  unite(`OR (95% CI; p-value)`, OR, CI_p, sep = " ") |>
  mutate(
    term_reference =
      ifelse(term_reference == "value vs. NA", "", term_reference)
    , variable =
      ifelse(duplicated(variable), "", variable)
  ) |>
  mutate(covariates = "", mediators = "") |>
  select(variable, term_reference, covariates, mediators, everything()) |>
  rename_at(1:4, str_to_sentence) |>
  rename_at("Term_reference", \(x) " ") |>
  kable(
    format = kable_format
    ,caption = "Table 10. Univariate regression analysis."
  ) |>
  footnote("*, p-value <= 0.05.") |>
  kable_classic()
```

```{r Filter significant univariate regression, include=FALSE}
univar_reg_sig <-
  univar_reg |>
  filter(term != '(Intercept)') |>
  filter(p.value <= 0.05) |>
  arrange(p.value)
```

```{r Obtain variables in sig uni reg results, include=FALSE}
univar_reg_sig_var <-
  univar_reg_sig |>
  pull(variable) |>
  unique()
```

# Multivariate regression analysis

```{r Determine adjustment, include=FALSE}
multivar_adjustment <-
  correlation_graph_df |>
  filter(from %in% univar_reg_sig_var & to %in% univar_reg_sig_var) |>
  right_join(data.frame(to = univar_reg_sig_var), by = join_by(to)) |>
  group_by(to) |>
  mutate(seq = seq(n())) |>
  rbind(
    univar_reg_sig |>
      select(to = variable) |>
      mutate(seq = 0, from = to)
  ) |>
  arrange(to, seq) |>
  mutate(
    from = 
      ifelse(
        str_remove_all(to, "_trans$") %in% var_num_non_normal_after_trans
        ,from
        ,ifelse(
          from %in% var_num_non_normal_after_trans
          ,paste0(from, "_trans")
          ,from
        )
      )
  ) |>
  group_by(to) |>
  summarize(covariates = paste0(from[!is.na(from)], collapse = "+")) |>
  rename(variable = to) |>
  mutate(formula = paste0(var$dependent, "~", covariates)) |>
  mutate(covariates = str_remove_all(covariates, paste0(variable, "\\+*"))) |>
  arrange(factor(variable, unique(univar_reg_sig$variable)))
```

```{r Conduct multivariate regression analysis, include=FALSE}
multivar_reg <-
  multivar_adjustment |>
  pull(formula) |>
  `names<-`(multivar_adjustment$variable) |>
  lapply(as.formula) |>
  lapply(glm, family = binomial(), data = processed_data) |>
  lapply(tidy) |>
  imap(~ mutate(.x, variable = .y)) |>
  reduce(rbind) |>
  select(variable, everything()) |>
  mutate(
    term = str_remove_all(term, variable)
    ,term = ifelse(term == "", "value", term)
    ,OR = exp(estimate)
    ,LB = exp(estimate - qnorm(0.975) * std.error)
    ,UB = exp(estimate + qnorm(0.975) * std.error)
  )
```

```{r table-11, echo=FALSE}
multivar_reg  |>
  filter(term != "(Intercept)") |>
  group_by(variable) |>
  slice(1) |>
  ungroup() |>
  select_at(c("variable", "term", "OR", "LB", "UB", "p.value")) |>
  mutate_at(3:6, round, 1) |>
  left_join(select(multivar_adjustment, -formula), by = join_by(variable)) |>
  select(variable, covariates, everything()) |>
  arrange(factor(variable, unique(univar_reg$variable))) |>
  filter(variable != "hba1c") |>
  left_join(
    processed_data |>
      lapply(levels) |>
      imap(
        ~ data.frame(variable = .y, reference = ifelse(is.null(.x), NA, .x))
      ) |>
      reduce(rbind)
    , by = join_by(variable)
  ) |>
  left_join(
    rename(colname_label, variable = colname)
    , by = join_by(variable)
  ) |>
  mutate(variable = label) |>
  select(-label) |>
  mutate_at(
    c("term", "reference")
    ,\(x) str_remove_all(x, "^[:digit:]+ - ")
  ) |>
  mutate_at(
    c("term", "reference")
    , \(x)
    str_replace_all(x, "oha", "OHA") |>
      str_replace_all("OHA_ins", "OHA + insulin")
  ) |>
  unite(term_reference, term, reference, sep = " vs. ") |>
  mutate(variable = paste0(variable, ifelse(p.value <= 0.05, "*", ""))) |>
  mutate(
    p.value =
      ifelse(p.value<0.001, "<0.001", round(p.value,3)) |>
      as.character()
  ) |>
  unite(CI, LB, UB, sep = ", ") |>
  unite(CI_p, CI, p.value, sep = "; ") |>
  mutate(CI_p = paste0("(", CI_p, ")")) |>
  unite(`OR (95% CI; p-value)`, OR, CI_p, sep = " ") |>
  mutate(
    term_reference =
      ifelse(term_reference == "value vs. NA", "", term_reference)
    , variable =
      ifelse(duplicated(variable), "", variable)
  ) |>
  left_join(
    rename(colname_label, covariates = colname)
    , by = join_by(covariates)
  ) |>
  mutate(covariates = ifelse(is.na(label), "", label)) |>
  select(-label) |>
  mutate(mediators = "") |>
  select(variable, term_reference, covariates, mediators, everything()) |>
  rename_at(1:4, str_to_sentence) |>
  rename_at("Term_reference", \(x) " ") |>
  kable(
    format = kable_format
    ,caption = "Table 2. Multivariate regression analysis."
  ) |>
  footnote("*, p-value <=0.05.") |>
  kable_classic()
```

```{r Filter significant multivariate regression, include=FALSE}
multivar_reg_sig <-
  multivar_reg  |>
  filter(term != "(Intercept)") |>
  group_by(variable) |>
  slice(1) |>
  ungroup() |>
  filter(p.value <= 0.05) |>
  arrange(p.value)
```

```{r Obtain variables in sig multi reg results, include=FALSE}
multivar_reg_sig_var <-
  multivar_reg_sig$variable |>
  unique()
```

# Mediation analysis

```{r Determine adjustment with each mediator, include=FALSE}
multivar_adjustment_mediator <-
  correlation_graph_df |>
  filter(from %in% multivar_reg_sig_var & to %in% multivar_reg_sig_var) |>
  select(from, to) |>
  left_join(
    multivar_adjustment |>
      select(from = variable, covariates)
    ,by = join_by(from)
  ) |>
  mutate(
    from = 
      ifelse(
        str_remove_all(to, "_trans$") %in% var_num_non_normal_after_trans
        ,from
        ,ifelse(
          from %in% var_num_non_normal_after_trans
          ,paste0(from, "_trans")
          ,from
        )
      )
  ) |>
  group_by(from, covariates) |>
  mutate(seq = seq(n())) |>
  ungroup()

multivar_adjustment_mediator <-
  multivar_adjustment_mediator |>
  rbind(
    group_by(multivar_adjustment_mediator, from, covariates) |>
      summarize(
        to = paste0(to[!is.na(to)], collapse="+")
        ,seq = max(seq) + 1
        ,.groups = "drop"
      )
  ) |>
  arrange(from, seq) |>
  rename(variable = from) |>
  rename(mediators = to) |>
  rename(confounders = covariates) |>
  mutate(
    formula=
      paste0(
        var$dependent
        ,"~"
        ,mapply(
          \(x,y,z) paste0(c(x,y,z)[c(x,y,z) != ""], collapse="+")
          ,variable
          ,confounders
          ,mediators
        )
      )
  ) |>
  select(variable, confounders, mediators, formula) |>
  unique() |>
  arrange(factor(variable, unique(multivar_reg_sig$variable)))
```

```{r Conduct mediation analysis, include=FALSE}
mediation <-
  multivar_adjustment_mediator |>
  pull(formula) |>
  `names<-`(
    paste0(
      multivar_adjustment_mediator$variable
      ,"|"
      ,multivar_adjustment_mediator$mediators
    )
  ) |>
  lapply(as.formula) |>
  lapply(glm, family = binomial(), data = processed_data) |>
  `names<-`(
    paste0(
      multivar_adjustment_mediator$variable
      ,"|"
      ,multivar_adjustment_mediator$mediators
    )
  ) |>
  lapply(tidy) |>
  imap(~ mutate(.x, variable = .y)) |>
  reduce(rbind) |>
  select(variable, everything()) |>
  separate(variable, c("variable", "mediators"), sep="\\|") |>
  mutate(
    term = str_remove_all(term, variable)
    ,term = ifelse(term == "", "value", term)
    ,OR = exp(estimate)
    ,LB = exp(estimate - qnorm(0.975) * std.error)
    ,UB = exp(estimate + qnorm(0.975) * std.error)
  )
```

```{r table-12, echo=FALSE}
mediation  |>
  filter(term != "(Intercept)") |>
  group_by(variable, mediators) |>
  slice(1) |>
  ungroup() |>
  select_at(c("variable", "mediators", "term", "OR", "LB", "UB", "p.value")) |>
  mutate_at(4:7, round, 1) |>
  left_join(select(multivar_adjustment, -formula), by=join_by(variable)) |>
  select(variable, covariates, everything()) |>
  left_join(
    processed_data |>
      lapply(levels) |>
      imap(
        ~ data.frame(variable = .y, reference = ifelse(is.null(.x), NA, .x))
      ) |>
      reduce(rbind)
    , by = join_by(variable)
  ) |>
  left_join(
    rename(colname_label, variable = colname)
    , by = join_by(variable)
  ) |>
  mutate(variable = label) |>
  select(-label) |>
  mutate_at(
    c("term", "reference")
    ,\(x) str_remove_all(x, "^[:digit:]+ - ")
  ) |>
  mutate_at(
    c("term", "reference")
    , \(x)
    str_replace_all(x, "oha", "OHA") |>
      str_replace_all("OHA_ins", "OHA + insulin")
  ) |>
  unite(term_reference, term, reference, sep = " vs. ") |>
  mutate(variable = paste0(variable, ifelse(p.value<=0.05,"*",""))) |>
  arrange(p.value) |>
  mutate(
    p.value=
      ifelse(p.value<0.001, "<0.001", round(p.value,3)) |>
      as.character()
  ) |>
  unite(CI, LB, UB, sep = ", ") |>
  unite(CI_p, CI, p.value, sep = "; ") |>
  mutate(CI_p = paste0("(", CI_p, ")")) |>
  unite(`OR (95% CI; p-value)`, OR, CI_p, sep = " ") |>
  mutate(
    term_reference =
      ifelse(term_reference == "value vs. NA", "", term_reference)
    , variable =
      ifelse(duplicated(variable), "", variable)
  ) |>
  left_join(
    rename(colname_label, covariates = colname)
    , by = join_by(covariates)
  ) |>
  mutate(covariates = ifelse(is.na(label), "", label)) |>
  select(-label) |>
  left_join(
    rename(colname_label, mediators = colname)
    , by = join_by(mediators)
  ) |>
  mutate(mediators = ifelse(is.na(label), "", label)) |>
  select(-label) |>
  select(variable, term_reference, covariates, mediators, everything()) |>
  rename_at(1:4, str_to_sentence) |>
  rename_at("Term_reference", \(x) " ") |>
  kable(
    format = kable_format
    ,caption = "Table 3. Mediation analysis."
  ) |>
  footnote("*, p-value <=0.05.") |>
  kable_classic()
```

```{r Filter significant multi reg for mediation analysis, include=FALSE}
multivar_reg_mediator_sig <-
  mediation  |>
  filter(term != "(Intercept)") |>
  group_by(variable) |>
  slice(1) |>
  ungroup() |>
  right_join(
    select(multivar_reg_sig, variable, p.value_multivar = p.value)
    , by = join_by(variable)
  ) |>
  filter(p.value <= 0.05 | is.na(p.value)) |>
  arrange(p.value_multivar) |>
  select(-p.value_multivar)
```

```{r Obtain variables in sig multi reg results for med analysis, include=FALSE}
multivar_reg_mediator_sig_var <-
  multivar_reg_mediator_sig$variable |>
  unique()
```

# Predictive modeling

```{r Select predictors based on multivar reg analysis, include=FALSE}
predictors <-
  multivar_reg_mediator_sig_var[
    !str_detect(multivar_reg_mediator_sig_var, "_trans$")
  ]
```

```{r Determine data for predictive modeling, include=FALSE}
predmod_data <-
  processed_data |>
  select_at(c(var$dependent, predictors)) |>
  mutate_at(var$dependent, \(x) as.integer(x == levels(x)[1])) |>
  mutate_if(is.factor, \(x) as.integer(x == levels(x)[2])) |>
  rename(outcome = fatigue) |>
  rownames_to_column(var = "id")
```

```{r Write data for predictive modeling, eval=FALSE, include=FALSE}
predmod_data |>
  write_csv("inst/extdata/predmod_data.csv")
```

```{r Determine machine learning algorithms, include=FALSE}
algorithms <-
  read_csv("inst/extdata/algorithms.csv", show_col_types = FALSE) |>
  mutate_all(\(x) factor(x, unique(x)))
```

# Model evaluation

```{r Load results of sample size estimation, include=FALSE}
sample_size_estimation <-
  algorithms$algorithm |>
  `names<-`(algorithms$algorithm) |>
  lapply(
    \(x)
    read_csv(
      paste0("inst/extdata/", x, "/sample_size_estimation.csv")
      , show_col_types = FALSE
    )
  ) |>
  imap(~ mutate(.x, algorithm = factor(.y, algorithms$algorithm))) |>
  reduce(rbind)
```

```{r Fit EPV-AUROC with modified exponential decay, include=FALSE}
mod_exp_decay <-
  algorithms$algorithm |>
  `names<-`(algorithms$algorithm) |>
  lapply(\(x) filter(sample_size_estimation, algorithm == x)) |>
  imap(
    ~ try(
        nls(
          auc_roc ~ 1 - a * exp(-k * epv)
          , data = .x
          , start = list(a = 1, k = 0.1)
        )
      )
  )
```

```{r Extract results of EPV-AUROC modified exp decay fitting, include=FALSE}
mod_exp_decay_results <-
  mod_exp_decay[sapply(mod_exp_decay, \(x) !is.character(x))] |>
  lapply(tidy) |>
  imap(~ mutate(.x, algorithm = factor(.y, algorithms$algorithm))) |>
  reduce(rbind) |>
  select(algorithm, term, estimate, p.value) |>
  mutate(
    p.value =
      case_when(
        p.value < 0.001 ~ "<0.001"
        ,p.value > 0.05 ~ ">0.05"
        ,TRUE ~ format(p.value, digits = 1)
      ) |>
      paste0(
        ifelse(term == "k", paste0("\nk=", round(estimate, 3)), "")
      )
  ) |>
  select(-estimate) |>
  spread(term, p.value)
```

```{r figure-4, echo=FALSE, fig.height=5, fig.width=7}
sample_size_estimation |>
  left_join(
    mod_exp_decay[sapply(mod_exp_decay, \(x) !is.character(x))] |>
      lapply(predict) |>
      imap(
        ~ data.frame(
            epv = filter(sample_size_estimation, algorithm == .y)$epv
            , auc_roc_med = .x
            , algorithm = factor(.y, algorithms$algorithm)
          )
      ) |>
      reduce(rbind)
    , by = join_by(epv, algorithm)
  ) |>
  left_join(algorithms, by = join_by(algorithm)) |>
  mutate(name = factor(str_wrap(name, 20), str_wrap(algorithms$name, 20))) |>
  ggplot(aes(epv, auc_roc)) +
  geom_smooth(method = "loess", formula = y ~ x) +
  geom_line(aes(y = auc_roc_med), color = "red", na.rm = TRUE) +
  geom_point() +
  geom_text(
    data =
      mod_exp_decay_results |>
      left_join(
        filter(sample_size_estimation, epv == min(epv))
        , by = join_by(algorithm)
      ) |>
      mutate(epv = 10, auc_roc = auc_roc - 0.025) |>
      left_join(algorithms, by = join_by(algorithm)) |>
      mutate(name = factor(str_wrap(name, 20), str_wrap(algorithms$name, 20)))
    , aes(label = paste0("p(a)=", a, "\np(k)=", k))
    , size = 3, hjust = 0, vjust = -0.1, check_overlap = TRUE
  ) +
  facet_wrap(~ name, ncol = 4, scales = "free_y") +
  xlab(
    "Number of samples with minority class of outcome per candidate predictor"
  ) +
  scale_y_continuous(
    "AUC-ROC"
    , breaks = seq(0, 1, 0.025)
    , labels = scales::label_number(accuracy = 0.025)
  )
```

Figure 4. Sample size estimation. Blue line indicates the LOESS. Red line indicates the modified exponential decay fitting. p(a) is the p-value of a where a is a parameter represents the factor by which the exponential term was scaled in the model and a higher value generally means a quicker initial increase. p(k) is the p-value of k where k is the rate of decay or growth in the exponential term and a positive k implies a decay (as x increases, the impact of increasing y diminishes) while a negative k suggests an erroneous model fit in this context because an increase in x should not lead to a decrease in y. AUC-ROC, the area under curve of receiver operating characteristics; LOESS, locally estimated scatterplot smoothing.

```{r Select algorithms of which the sample size is sufficient, include=FALSE}
algo_suff_sampsize <-
  mod_exp_decay_results |>
  separate(k, c("k_p.value", "k_estimate"), sep = "\nk=") |>
  mutate_at(
    c("a", "k_p.value", "k_estimate")
    , \(x) suppressWarnings(as.numeric(ifelse(x == "<0.001", 0.001, x)))
  ) |>
  filter(a <= 0.05 & k_p.value <= 0.05 & k_estimate >= 0) |>
  pull(algorithm)
```

```{r Create empty list for model evaluation, include=FALSE}
eval <- list()
```

```{r Obtain the model evaluation data, include=FALSE}
eval$df <-
  algo_suff_sampsize |>
  `names<-`(algo_suff_sampsize) |>
  lapply(
    \(x)
    obtain_obs_pred("predmod_data", "inst/extdata/", paste0("inst/extdata/", x))
  )
```

```{r Evaluate calibration, include=FALSE}
eval$calibration <-
  eval$df |>
  lapply(calibration, seed = seed)
```

```{r Evaluate decision, include=FALSE}
eval$decision <-
  eval$df |>
  lapply(select, -id) |>
  lapply(decision, seed = seed)
```

```{r Evaluate discrimination, include=FALSE}
eval$discrimination <-
  eval$df |>
  lapply(select, -id) |>
  lapply(discrimination, seed = seed)
```

```{r Determine threshold, include=FALSE}
eval$threshold <-
  eval$df |>
  lapply(select, -id) |>
  lapply(
    thresholding
    , standard = FALSE, optimal = FALSE, clinical = TRUE, seed = seed
  )
```

```{r Assign threshold, include=FALSE}
th <-
  eval$threshold |>
  lapply(filter, metric == "th") |>
  lapply(pull, avg)
```

```{r Evaluate model, include=FALSE}
eval_plot_df <-
  algo_suff_sampsize |>
  as.character() |>
  `names<-`(algo_suff_sampsize) |>
  lapply(
    \(x)
    list(
      calibration = eval$calibration[[x]]
      , decision = eval$decision[[x]]
      , discrimination = eval$discrimination[[x]]
    )
  )
```

```{r figure-5, fig.height=12, fig.width=10}
ggarrange(
  eval_plot_df$knn |>
    arrange_eval_plot(
      threshold = th$knn
      , dc_xby = 0.2, dc_ymax = 0.5, dc_yby = 0.1, dc_ta_angle = -70
      , labels = LETTERS[1:3]
    )
  , eval_plot_df$dt |>
    arrange_eval_plot(
      threshold = th$dt
      , dc_xby = 0.2, dc_ymax = 0.5, dc_yby = 0.1, dc_ta_angle = -70
      , labels = LETTERS[4:6]
    )
  , eval_plot_df$rf |>
    arrange_eval_plot(
      threshold = th$rf
      , dc_xby = 0.2, dc_ymax = 0.5, dc_yby = 0.1, dc_ta_angle = -70
      , labels = LETTERS[7:9]
    )
  , nrow = 3, ncol = 1
  , heights = c(4, 4, 4)
)
```

```{r Obtain pre-computed SHAPs of the models, include=FALSE}
shap_values <-
  paste0(
    "inst/extdata/", algo_suff_sampsize, "/shap_values.csv"
  ) |>
  `names<-`(algo_suff_sampsize) |>
  lapply(read_csv, show_col_types = FALSE)
```

```{r Combine SHAP with features of the models, include=FALSE}
shap_feature_values <-
  shap_values |>
  lapply(mutate, seq = seq(n())) |>
  lapply(gather, feature, shap_value, -seq) |>
  imap(
    ~ .x |>
      left_join(
        predmod_data |>
          select(-id, -outcome) |>
          mutate(seq = seq(n())) |>
          gather(feature, feature_value, -seq)
        , by = join_by(seq, feature)
      )
  ) |>
  imap(
    ~ .x |>
      left_join(
        eval$df[[.y]] |>
          mutate(seq = seq(n()))
        ,by = join_by(seq)
      )
  )
```

```{r Plot regression analysis of the predictors, include=FALSE}
predmod_reg_plot <-
  multivar_reg_sig |>
  filter(
    !variable %in% filter(multivar_reg_mediator_sig, !is.na(OR))$variable
  ) |>
  rbind(select(filter(multivar_reg_mediator_sig, !is.na(OR)), -mediators)) |>
  filter(variable != "hba1c") |>
  mutate_at("variable", str_remove_all, "_trans") |>
  mutate(type = "SCM") |>
  rbind(
    eval$df |>
      imap(~ obtain_model_feature_effect_size(.x, th = th[[.y]])) |>
      imap(~ mutate(.x, type = str_to_upper(.y))) |>
      reduce(rbind)
  ) |>
  mutate_at("type", \(x) factor(x, unique(x))) |>
  left_join(
    rename(colname_label, variable = colname), by = join_by(variable)
  ) |>
  mutate(variable = label) |>
  select(-label) |>
  reg_analysis_plot(strata = "type")
```

```{r SHAP beeswarm plot of KNN, include=FALSE}
shap_beeswarm_plots <-
  shap_feature_values |>
  lapply(
    \(x)
    x |>
      left_join(
        rename(colname_label, feature = colname), by = join_by(feature)
      ) |>
      mutate(feature = label) |>
      shap_beeswarm_plot(seed, transparency = 1)
  )
```

```{r figure-6, echo=FALSE, fig.height=7, fig.width=7}
ggarrange(
  predmod_reg_plot
  , shap_beeswarm_plots$knn
  , shap_beeswarm_plots$dt
  , shap_beeswarm_plots$rf
  , nrow = 4, ncol = 1
  , heights = c(2, 2, 2, 2)
  , labels = LETTERS[1:4]
)
```

Figure 6. Model explainability: (A) regression analysis of the predictors; (B) SHAP beeswarm plot of KNN; (C) SHAP beeswarm plot of DT; and (D) SHAP beeswarm plot of RF. CI, confidence interval; DM, diabetes mellitus; DT, decision tree; KNN, k-nearest neighbor; OHA, oral hypoglycemic agent; OR, odds ration; RF, random forest; SCM, structural causal model; SHAP, Shapley additive explanation.

```{r Predmod decision curve plots, include=FALSE}
predmod_decision_curve <-
  data.frame(th = NA, nb = NA, type = "SCM") |>
  rbind(mutate(eval_plot_df$knn$decision$plot$data, type = "KNN")) |>
  rbind(mutate(eval_plot_df$dt$decision$plot$data, type = "DT")) |>
  rbind(mutate(eval_plot_df$rf$decision$plot$data, type = "RF")) |>
  left_join(
    th |>
      imap(~ data.frame(type = str_to_upper(.y), threshold = .x)) |>
      reduce(rbind)
    , by = join_by(type)
  ) |>
  mutate_at("type", \(x) factor(x, unique(x))) |>
  ggplot(aes(th, nb, color = type)) +
  geom_hline(yintercept = 0, lty = 2) +
  annotate(
    "text", 0, 0, label = "treat none"
    , hjust = 0, vjust = -0.4, size = 3
  ) +
  geom_abline(
    slope = -1, intercept = eval_plot_df$knn$decision$prevalence
    , lty = 2
  ) +
  annotate(
    "text"
    , 0, eval_plot_df$knn$decision$prevalence
    , angle = -75, label = "treat all"
    , hjust = -0.4, vjust = 1.4, size = 3
  ) +
  geom_path(, na.rm = TRUE) +
  geom_point(
    aes(x = ifelse(th == threshold, th, NA)), size = 2, na.rm = TRUE
  ) +
  scale_x_continuous(
    "Threshold"
    , breaks = seq(0, 1, 0.2)
    , limits = c(0, 1)
  ) +
  scale_y_continuous(
    "Net benefit"
    , breaks = seq(0, 1, 0.1)
    , limits = c(0, 0.5)
  ) +
  theme_classic() +
  theme(legend.position = "none")
```

```{r Predmod ROC curve, include=FALSE}
predmod_roc_curve <-
  data.frame(th = NA, tpr = NA, tnr = NA, type = "SCM") |>
  rbind(mutate(eval_plot_df$knn$discrimination$plot$data, type = "KNN")) |>
  rbind(mutate(eval_plot_df$dt$discrimination$plot$data, type = "DT")) |>
  rbind(mutate(eval_plot_df$rf$discrimination$plot$data, type = "RF")) |>
  left_join(
    th |>
      imap(~ data.frame(type = str_to_upper(.y), threshold = .x)) |>
      reduce(rbind)
    , by = join_by(type)
  ) |>
  mutate_at("type", \(x) factor(x, unique(x))) |>
  ggplot(aes(tnr, tpr, color = type)) +
  geom_abline(slope = 1, intercept = 1, lty = 2) +
  geom_path(na.rm = TRUE) +
  geom_point(aes(x=ifelse(th == threshold, tnr, NA)), na.rm = TRUE) +
  coord_equal() +
  scale_x_reverse(
    "Specificity", breaks = seq(0, 1, 0.1), limits = c(1, 0)
  ) +
  scale_y_continuous(
    "Sensitivity", breaks = seq(0, 1, 0.1), limits = c(0, 1)
  ) +
  theme_classic() +
  theme(legend.position = "none")
```

```{r Model evaluation plots, include=FALSE}
model_evaluation_plot <-
  ggarrange(
    ggarrange(
      eval_plot_df$knn$calibration |>
        arrange_calib_plot(th$knn)
      , eval_plot_df$dt$calibration |>
        arrange_calib_plot(th$dt)
      , eval_plot_df$rf$calibration |>
        arrange_calib_plot(th$rf)
      , nrow = 3, ncol = 1
      , heights = c(4, 4, 4)
      , labels = LETTERS[1:3]
    )
    , ggarrange(
        ggarrange(
          predmod_decision_curve
          , predmod_roc_curve
          , nrow = 1, ncol = 2
          , widths = c(4, 6)
          , labels = LETTERS[4:5]
        )
        , ggarrange(
            predmod_reg_plot
            , shap_beeswarm_plots$knn
            , shap_beeswarm_plots$dt
            , shap_beeswarm_plots$rf
            , nrow = 4, ncol = 1
            , heights = c(2, 2, 2, 2)
            , labels = LETTERS[6:9]
          )
        , nrow = 2, ncol = 1
        , heights = c(4, 8)
      )
    , nrow = 1, ncol = 2
    , widths = c(5, 10)
  )
```

```{r figure-7, echo=FALSE, fig.height=12, fig.width=10}
model_evaluation_plot
```
Figure 7. Model evaluation for calibration (A-C), clinical utility (D), discrimination ability (E), and explainability and interpretability (F-J). Calibration and SHAP beeswarm plots are shown for KNN (A and G), DT (B and H), and RF (C and I). Color legends indicating the models are shared among decision curve (D), ROC curve (E), and regression analysis of the predictors using the predicted outcome as the dependent variable (F). Points in decision and ROC curves (D, E) correspond to the chosen threshold closest to 95% specificity in our data. CI, confidence interval; DM, diabetes mellitus; DT, decision tree; KNN, k-nearest neighbor; OHA, oral hypoglycemic agent; OR, odds ration; RF, random forest; ROC, receiver operating characteristics; SCM, structural causal model; SHAP, Shapley additive explanation.

```{r Fig. 2, eval=FALSE, fig.height=12, fig.width=10, include=FALSE}
model_evaluation_plot
# Proportionally resized by width = 5.51181 incches
ggsave("doc/figure2.eps", height = 12, width = 10, units = "in")
```

```{r Compute CM using the threshold, include=FALSE}
eval$cm <-
  eval$df |>
  imap(
    ~ thresholding(
        .x
        , custom_metric = "th", custom_ref = th[[.y]]
        , standard = FALSE, optimal = FALSE, clinical = FALSE, seed = seed
      )
  )
```

```{r Summarize confusion matrix, include=FALSE}
cm_summary <-
  eval[c("calibration", "decision", "discrimination")] |>
  lapply(\(x) reduce(imap(x, ~ mutate(.x$metrics, model = .y)), rbind)) |>
  reduce(rbind) |>
  filter(term %in% c("AUC-ROC")) |>
  mutate(lb = estimate - ci, ub = estimate + ci) |>
  select(-ci) |>
  select(model, metric = term, avg = estimate, everything()) |>
  rbind(
    eval$cm |>
      imap(~ mutate(.x, model = .y)) |>
      reduce(rbind) |>
      filter(ref_type == "TH" & !metric %in% c("th", "nb")) |>
      mutate(metric = str_to_upper(metric)) |>
      select(-ref_type, -ref_value) |>
      select(model, metric, avg, everything())
  ) |>
  mutate(
    avg =
      ifelse(
        metric == "AUC-ROC"
        , round(avg, 3)
        , ifelse(metric == "F1", round(avg, 2), round(avg, 1))
      )
    , lb =
      ifelse(
        metric == "AUC-ROC"
        , round(lb, 3)
        , ifelse(metric == "F1", round(lb, 2), round(lb, 1))
      )
    , ub =
      ifelse(
        metric == "AUC-ROC"
        , round(ub, 3)
        , ifelse(metric == "F1", round(ub, 2), round(ub, 1))
      )
  ) |>
  unite(ci, lb, ub, sep = ", ") |>
  mutate_at("ci", \(x) paste0("(", x, ")")) |>
  unite(summary, avg, ci, sep = " ") |>
  mutate(
    model = factor(model, unique(model))
    , metric = factor(metric, c("AUC-ROC", "F1", "TNR", "TPR", "PPV", "NPV"))
  ) |>
  spread(metric, summary) |>
  left_join(
    reduce(imap(th, ~ data.frame(model = .y, TH = .x)), rbind)
    , by = join_by(model)
  ) |>
  select(model, `AUC-ROC`, TH, everything())
```

```{r table-13, echo=FALSE}
cm_summary |>
  mutate_at("model", str_to_upper) |>
  rename(Model = model) |>
  kable(
    caption = "Table 13. Predictive performance."
    , format = kable_format
  ) |>
  footnote(
    paste0(
      "AUC-ROC, area under the curve - receiver operating characteristics; "
      , "DT, decision tree; "
      , "F1, the F1-score; "
      , "KNN, k-nearest neighbor; "
      , "TH, the chosen threshold closest to 95% specificity in our data; "
      , "NPV, negative predictive value; "
      , "PPV, positive predictive value (precision); "
      , "RF, random forest; "
      , "TNR, true negative rate (specificity); "
      , "TPR, true positive rate (sensitivity/recall)."
    )
  ) |>
  kable_classic() |>
  column_spec(1:7, extra_css = "vertical-align:top;")
```

```{r Determine best_model, include=FALSE}
best_model <- as.character(algo_suff_sampsize[3])
```

```{r Classify confusion matrix by the best model, include=FALSE}
best_model_cm <-
  eval$df[[best_model]] |>
  mutate(pred = factor(as.integer(pred >= th[[best_model]]))) |>
  mutate(
    cm =
      case_when(
        obs == 1 & pred == 1 ~ "TP"
        , obs == 1 & pred == 0 ~ "FN"
        , obs == 0 & pred == 1 ~ "FP"
        , obs == 0 & pred == 0 ~ "TN"
      ) |>
      factor(c("TP", "FP", "TN", "FN"))
  ) |>
  select(id, cm) |>
  column_to_rownames(var = "id")
```

```{r Fit PCA model using variables, include=FALSE}
pca_model <-
  processed_data |>
  select_if(!str_detect(colnames(processed_data), "_trans$")) |>
  colnames() |>
  lapply(binarize_cat_var, processed_data) |>
  reduce(cbind) |>
  prcomp()
```

```{r Fit ontology model using variables, include=FALSE}
ontology_model <-
  processed_data |>
  select_if(!str_detect(colnames(processed_data), "_trans$")) |>
  colnames() |>
  lapply(binarize_cat_var, processed_data) |>
  reduce(cbind) |>
  t() |>
  dist(method = "euclidean") |>
  hclust(method = "complete")
```

```{r Fit ontology model 2 using PCs, include=FALSE}
ontology_model2 <-
  pca_model$x |>
  t() |>
  dist(method = "euclidean") |>
  hclust(method = "complete")
```

```{r figure-8, echo=FALSE, fig.height=7, fig.width=7}
ggarrange(
  ggarrange(
    NULL
    , data.frame(
        pc = colnames(pca_model$rotation)
        , pve = (pca_model$sdev^2 / sum(pca_model$sdev^2)) * 100
      ) |>
      left_join(
        data.frame(
          pc = ontology_model2$labels
          , order2 = ontology_model2$order
          , hcluster2 = cutree(ontology_model2, k = 4)
        )
        , by = join_by(pc)
      ) |>
      mutate_at("pc", \(x) factor(x, unique(x))) |>
      ggplot(aes(pc, pve)) +
      geom_vline(xintercept = seq(14) + 0.5, color = "grey") +
      geom_col() +
      facet_grid(~ hcluster2, scales = "free_x", space = "free_x") +
      scale_y_continuous("Proportion of\nvariance explained (%)") +
      theme(
        panel.grid = element_blank()
        , axis.title.x = element_blank()
        , axis.ticks.x = element_blank()
        , axis.text.x = element_blank()
      )
    , NULL
    , nrow = 1, ncol = 3
    , widths = c(6.45, 12.85, 0.7)
  )
  , as.data.frame(pca_model$rotation) |>
    rownames_to_column(var = "variable") |>
    gather(pc, weight, -variable) |>
    left_join(
      data.frame(
        variable = ontology_model$labels
        , order = ontology_model$order
        , hcluster = cutree(ontology_model, k = 6)
      )
      , by = join_by(variable)
    ) |>
    left_join(
      data.frame(
        pc = ontology_model2$labels
        , order2 = ontology_model2$order
        , hcluster2 = cutree(ontology_model2, k = 4)
      )
      , by = join_by(pc)
    ) |>
    mutate(
      term = sapply(variable, \(x) str_extract_all(x, "_[:digit:]+$")[[1]])
      , term =
        ifelse(
          sapply(term, length) == 0
          , ""
          , sapply(term, \(x) str_remove_all(unlist(x)[1], "_"))
        )
      , variable = str_remove_all(variable, "_[:digit:]+$")
    ) |>
    mutate(
      term =
        ifelse(
          term == ""
          & variable
            %in% colnames(processed_data)[sapply(processed_data, is.factor)]
          , "2"
          , term
        )
    ) |>
    left_join(
      processed_data[sapply(processed_data, \(x) !is.null(levels(x)))] |>
        lapply(levels) |>
        imap(
          ~ data.frame(
              variable = .y
              , term = as.character(seq(length(.x)))
              , level =
                str_remove_all(.x, "^[:digit:] - ") |>
                str_replace_all("oha", "OHA") |>
                str_replace_all("OHA_ins", "OHA + insulin")
            )
        ) |>
        reduce(rbind)
      , by = join_by(variable, term)
    ) |>
    left_join(
      rename(colname_label, variable = colname), by = join_by(variable)
    ) |>
    mutate(variable = label) |>
    select(-label) |>
    mutate(
      variable =
        paste0(
          variable
          , ifelse(term == "" & is.na(level), "", paste0(" (=", level, ")"))
        )
    ) |>
    mutate_at("pc", \(x) factor(x, unique(x))) |>
    mutate(variable = reorder(variable, rev(order))) |>
    ggplot(aes(pc, variable, fill = weight)) +
    geom_tile(color = "white") +
    facet_grid(hcluster ~ hcluster2, scales = "free", space = "free") +
    # coord_equal() +
    xlab("Reduced dimension") +
    ylab("Original dimension") +
    scale_fill_gradient2(
      "Weight", low = "blue", mid = "black", high = "red", midpoint = 0
    ) +
    theme(
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
      , legend.position = "bottom"
      , strip.text.x.top = element_blank()
    )
  , nrow = 2, ncol = 1
  , heights = c(2, 5)
)
```
Figure 8. Principal component analysis with original and reduced dimensional ontologies using hierarchical clustering. Ontologies were derived by cutting hierarchical cluster tree such that the resulting groups demonstrated meaningful pattern. It was determined based on visual assessment of the weights and semantic assessment of the original dimensions. The former resulted in six ontologies of the reduced dimensions, while the latter resulted in four ontologies of the original dimensions. DM, diabetes mellitus; OHA, oral hypoglycemic agent.

```{r Fit k-mean model using PC1 and PC2, include=FALSE}
set.seed(seed)
kmean_model <-
  processed_data |>
  select(age) |>
  kmeans(2, algorithm = "Hartigan-Wong")
```

```{r Combine data and the results of CM-PCA-kmean, include=FALSE}
data_cm_pc_kmean <-
  processed_data |>
  rownames_to_column(var = "id") |>
  left_join(rownames_to_column(best_model_cm, var = "id"), by = join_by(id)) |>
  left_join(
    rownames_to_column(as.data.frame(pca_model$x), var = "id")
    , by = join_by(id)
  ) |>
  left_join(
    data.frame(cluster = factor(kmean_model$cluster)) |>
      rownames_to_column(var = "id")
    , by = join_by(id)
  )
```

```{r figure-9, echo=FALSE, fig.height=3.5, fig.width=7}
mutate(data_cm_pc_kmean, cm = "All") |>
  rbind(data_cm_pc_kmean) |>
  mutate_at("cm", \(x) factor(x, unique(x))) |>
  ggplot(aes(age, fill = cluster)) +
  geom_density() +
  geom_vline(xintercept = 53.5, lty = 2) +
  facet_grid(cm ~ ., scales = "free_y") +
  scale_x_continuous(
    "Age (years)"
    , breaks = sort(c(seq(40, 65, 5), 53.5))
    , labels = sort(c(seq(40, 65, 5), 53.5))
  ) +
  ylab("Density") +
  scale_fill_discrete("Cluster") +
  theme(panel.grid.minor.x = element_blank())
```
Figure 9. Sample clustering by k-mean. We selected k=2 post hoc because it provided samples for each cluster among true and false positives and negatives, completely. Age was selected for clustering the samples because it almost singlehandedly determined a principal component that had the highest proportion of the variance explained in our data. FN, false negative; FP, false positive; TN, true negative; TP, true positive.

```{r Randomly select examples from cluster-CM combinations, include=FALSE}
comb_cluster_cm <-
  expand.grid(
    cluster = levels(data_cm_pc_kmean$cluster)
    , cm = levels(data_cm_pc_kmean$cm)
    , stringsAsFactors = FALSE
  ) |>
  mutate(id = as.character(NA))

for(i in seq(nrow(comb_cluster_cm))){
  set.seed(seed)
  comb_cluster_cm$id[i] <-
    data_cm_pc_kmean |>
    filter(cluster == comb_cluster_cm$cluster[i]) |>
    filter(cm == comb_cluster_cm$cm[i]) |>
    pull(id) |>
    sample(1)
}

rm(i)
```

```{r Format the waterfall data, include=FALSE}
waterfall_formatted_data <-
  shap_feature_values[[best_model]] |>
  left_join(
    processed_data |>
      select_at(
        predictors[
          !sapply(select_at(processed_data, predictors), is.numeric)
        ]
      ) |>
      as.list() |>
      `names<-`(
        predictors[
          !sapply(select_at(processed_data, predictors), is.numeric)
        ]
      ) |>
      lapply(levels) |>
      imap(~ data.frame(variable = .y, category = .x)) |>
      reduce(rbind) |>
      separate(category, c("level", "category"), sep = " - ") |>
      mutate(level = as.numeric(level==2)) |>
      rename(feature = variable, feature_value = level)
    , by = join_by(feature, feature_value)
  ) |>
  mutate(
    category =
      ifelse(
        feature == "dm_treatment" & category == "oha"
        , "no", category
      )
    , category =
      ifelse(
        feature == "dm_treatment" & category == "oha_ins"
        , "yes", category
      )
  ) |>
  left_join(
    rename(colname_label, feature = colname), by = join_by(feature)
  ) |>
  mutate(feature = label) |>
  select(-label) |>
  mutate(
    feature =
      ifelse(
        is.na(category)
        , paste0(feature," (=", feature_value, ")")
        , paste0(feature," (=", category, ")")
      )
  )
```

```{r Compute average predicted outcome probability of dev data, include=FALSE}
exp_prob =
  shap_feature_values[[best_model]] |>
  select(id, prob = pred) |>
  unique() |>
  pull(prob) |>
  mean()
```

```{r Compute average true outcome probability of dev data, include=FALSE}
exp_obs =
  shap_feature_values[[best_model]] |>
  mutate(obs = as.numeric(obs == levels(obs)[2])) |>
  select(seq, obs) |>
  unique() |>
  pull(obs) |>
  mean()
```

```{r Plot SHAP waterfall for all the examples, include=FALSE}
shap_waterfall_selected_id <-
  comb_cluster_cm$id |>
  `names<-`(comb_cluster_cm$id) |>
  lapply(
    shap_waterfall_plot
    , waterfall_formatted_data |>
        left_join(
          select(data_cm_pc_kmean, id, cluster, cm), by = join_by(id)
        ) |>
        mutate(
          cluster =
            ifelse(cluster == 1, "<= 53 years old", ">53 years old") |>
            factor(c("<= 53 years old", ">53 years old"))
        )
    , threshold = th[[best_model]]
    , exp_prob = exp_prob
    , exp_obs = exp_obs
  )
```

```{r figure-10, fig.height=4.5, fig.width=10}
ggarrange(
  arrange_waterfall_plot(
    "TP", shap_waterfall_selected_id, comb_cluster_cm, top = TRUE
  )
  , arrange_waterfall_plot("FP", shap_waterfall_selected_id, comb_cluster_cm)
  , arrange_waterfall_plot("TN", shap_waterfall_selected_id, comb_cluster_cm)
  , arrange_waterfall_plot(
      "FN", shap_waterfall_selected_id, comb_cluster_cm, bottom = TRUE
    )
  , nrow = 4, ncol = 1, heights = c(1.25, 1, 1, 1.25)
)
```
Figure 10. Error analysis on the selected examples by SHAP waterfall plots. SHAP, Shapley additive explanation. OHA, oral hypoglycemic agent.

# Model deployment

```{r Determine data for model deployment, include=FALSE}
depmod_data <-
  expand.grid(
    hba1c = seq(min(predmod_data$hba1c), max(predmod_data$hba1c), 0.1)
    , comorbidity = unique(predmod_data$comorbidity)
    , dm_treatment = unique(predmod_data$dm_treatment)
  ) |>
  mutate(
    id = str_pad(seq(n()), 3, "left", 0)
    , outcome = as.integer(NA)
  ) |>
  select_at(colnames(predmod_data))
```

```{r Write data for model deployment, eval=FALSE, include=FALSE}
depmod_data |>
  write_csv("inst/extdata/depmod_data.csv")
```

```{r Obtain the best model probability, include=FALSE}
best_model_prob <-
  obtain_obs_pred("depmod_data", "inst/extdata/", "inst/extdata/best_model")
```

```{r Obtain pre-computed SHAPs of the best model, include=FALSE}
best_model_shap_values <-
  paste0("inst/extdata/best_model/shap_values.csv") |>
  read_csv(show_col_types = FALSE)
```

```{r Combine SHAP with features of the best model, include=FALSE}
best_model_shap_feature_values <-
  best_model_shap_values |>
  mutate(seq = seq(n())) |>
  gather(feature, shap_value, -seq) |>
  left_join(
    depmod_data |>
      select(-id, -outcome) |>
      mutate(seq = seq(n())) |>
      gather(feature, feature_value, -seq)
    , by = join_by(seq, feature)
  ) |>
  left_join(
    best_model_prob |>
      mutate(seq = seq(n()))
    ,by = join_by(seq)
  ) |>
  mutate(obs = factor(as.integer(pred >= th[[best_model]])))
```

```{r Deployment data with scenario, include=FALSE}
depmod_data_scenario <-
  depmod_data |>
  filter(hba1c %in% c(6.0, 8.0)) |>
  mutate(
    cluster = ifelse(hba1c >= 6.5, 2, 1)
    , cm =
      case_when(
        comorbidity == 0 & dm_treatment == 0 ~ "OHA"
        , comorbidity == 0 & dm_treatment == 1 ~ "OHA+Insulin"
        , comorbidity == 1 & dm_treatment == 0 ~ "OHA with\ncomorbidity"
        , comorbidity == 1 & dm_treatment == 1 ~ "OHA+Insulin\nwith comorbidity"
      )
  )
```

```{r Create scenario, include=FALSE}
comb_scenario <-
  depmod_data_scenario |>
  filter(
    (cluster == 1 & cm == "OHA")
    | (cluster == 1 & cm == "OHA+Insulin")
    | (cluster == 1 & cm == "OHA with\ncomorbidity")
    | (cluster == 1 & cm == "OHA+Insulin\nwith comorbidity")
    | (cluster == 2 & cm == "OHA")
    | (cluster == 2 & cm == "OHA+Insulin")
    | (cluster == 2 & cm == "OHA with\ncomorbidity")
    | (cluster == 2 & cm == "OHA+Insulin\nwith comorbidity")
  )
```

```{r Format the deployment data, include=FALSE}
dep_formatted_data =
  best_model_shap_feature_values |>
  left_join(
    processed_data |>
      select_at(
        predictors[
          !sapply(select_at(processed_data, predictors), is.numeric)
        ]
      ) |>
      as.list() |>
      `names<-`(
        predictors[
          !sapply(select_at(processed_data, predictors), is.numeric)
        ]
      ) |>
      lapply(levels) |>
      imap(~ data.frame(variable = .y, category = .x)) |>
      reduce(rbind) |>
      separate(category, c("level", "category"), sep = " - ") |>
      mutate(level = as.numeric(level==2)) |>
      rename(feature = variable, feature_value = level)
    , by = join_by(feature, feature_value)
  ) |>
  mutate(
    category =
      ifelse(
        feature == "dm_treatment" & category == "oha"
        , "no", category
      )
    , category =
      ifelse(
        feature == "dm_treatment" & category == "oha_ins"
        , "yes", category
      )
  ) |>
  left_join(
    rename(colname_label, feature = colname), by = join_by(feature)
  ) |>
  mutate(feature = label) |>
  select(-label) |>
  mutate(
    feature =
      ifelse(
        is.na(category)
        , paste0(feature," (=", feature_value, ")")
        , paste0(feature," (=", category, ")")
      )
  )
```

```{r Plot SHAP waterfall for all the scenario, include=FALSE}
shap_waterfall_selected_scenario <-
  comb_scenario$id |>
  `names<-`(comb_scenario$id) |>
  lapply(
    shap_waterfall_plot
    , dep_formatted_data |>
      left_join(
        select(depmod_data_scenario, id, cluster, cm), by = join_by(id)
      ) |>
      mutate(
        cluster =
          ifelse(cluster == 1, "HbA1c < 6.5", "HbA1c 6.5+") |>
          factor(c("HbA1c < 6.5", "HbA1c 6.5+"))
      )
    , threshold = th[[best_model]]
    , exp_prob = exp_prob
    , exp_obs = exp_obs
  )
```

```{r figure-11, fig.height=4.75, fig.width=10}
ggarrange(
  arrange_waterfall_plot(
    "OHA"
    , shap_waterfall_selected_scenario, comb_scenario, top = TRUE
  )
  , arrange_waterfall_plot(
      "OHA+Insulin"
      , shap_waterfall_selected_scenario, comb_scenario
    )
  , arrange_waterfall_plot(
      "OHA with\ncomorbidity"
      , shap_waterfall_selected_scenario, comb_scenario
    )
  , arrange_waterfall_plot(
      "OHA+Insulin\nwith comorbidity"
      , shap_waterfall_selected_scenario, comb_scenario, bottom = TRUE
    )
  , nrow = 4, ncol = 1, heights = c(1.25, 1, 1, 1.5)
)
```

```{r Combine dataframe for creating nomogram, include=FALSE}
nomogram_data <-
  depmod_data |>
  mutate(
    cm =
      case_when(
        comorbidity == 0 & dm_treatment == 0 ~ "OHA"
        , comorbidity == 0 & dm_treatment == 1 ~ "OHA+Insulin"
        , comorbidity == 1 & dm_treatment == 0 ~ "OHA with\ncomorbidity"
        , comorbidity == 1 & dm_treatment == 1 ~ "OHA+Insulin\nwith comorbidity"
      ) |>
      factor(
        c("OHA"
          , "OHA+Insulin"
          , "OHA with\ncomorbidity"
          , "OHA+Insulin\nwith comorbidity"
          
        )
      )
  ) |>
  left_join(best_model_prob, by = join_by(id)) |>
  select(id, cm, hba1c_value = hba1c, prob = pred) |>
  cbind(best_model_shap_values) |>
  gather(metric, value, -id, -cm, -hba1c_value) |>
  mutate(type = ifelse(metric == "prob", "prob", "shap"))
```

```{r Create nomogram}
nomogram <-
  ggarrange(
    ggarrange(
      data.frame(h = 1, v = 5, l = "Comorbidity last 3 months?", b = 1) |>
        rbind(data.frame(h = 2, v = 5+2.5, l = "No", b = 1)) |>
        rbind(data.frame(h = 2, v = 5-2.5, l = "Yes", b = 1)) |>
        rbind(
          data.frame(h = 3, v = 5+2.5, l = "Insulin last 3 months?", b = 2)
        ) |>
        rbind(data.frame(h = 4, v = 5+2.5+1.25, l = "No", b = 2)) |>
        rbind(data.frame(h = 4, v = 5+2.5-1.25, l = "Yes", b = 2)) |>
        rbind(
          data.frame(h = 3, v = 5-2.5, l = "Insulin last 3 months?", b = 2)
        ) |>
        rbind(data.frame(h = 4, v = 5-2.5+1.25, l = "No", b = 2)) |>
        rbind(data.frame(h = 4, v = 5-2.5-1.25, l = "Yes", b = 2)) |>
        rbind(
          data.frame(h = 5, v = 5+2.5+1.25, l = "HbA1c last 3 months?", b = 3)
        ) |>
        rbind(
          data.frame(h = 5, v = 5+2.5-1.25, l = "HbA1c last 3 months?", b = 3)
        ) |>
        rbind(
          data.frame(h = 5, v = 5-2.5+1.25, l = "HbA1c last 3 months?", b = 3)
        ) |>
        rbind(
          data.frame(h = 5, v = 5-2.5-1.25, l = "HbA1c last 3 months?", b = 3)
        ) |>
        mutate(b = factor(b)) |>
        mutate(i = h + 1, j = v) |>
        ggplot(aes(h, v)) +
        geom_text(
          data = data.frame(h = c(1-0.25, 5+0.25), v = c(0, 10), l = c("", ""))
          , aes(label = l)
        ) +
        geom_edges(
          aes(xend = i, yend = j)
          , arrow = arrow(length = unit(0.15, "line"), type = "closed")
        ) +
        geom_edges(
          data =
            data.frame(h = 2, v = 5-2.5, i = 2, j = 5+2.5) |>
            rbind(data.frame(h = 4, v = 5+2.5-1.25, i = 4, j = 5+2.5+1.25)) |>
            rbind(data.frame(h = 4, v = 5-2.5-1.25, i = 4, j = 5-2.5+1.25))
          , aes(xend = i, yend = j)
        ) +
        geom_label(
          aes(label = l, fill = b)
          , size = 2.25, angle = 90, show.legend = FALSE
        ) +
        theme_blank()
      , NULL
      , nrow = 2, ncol = 1
      , heights = c(6.75, 0.25)
    )
    , nomogram_data |>
      filter(type == "prob") |>
      ggplot(aes(value, hba1c_value)) +
      geom_vline(xintercept = th[[best_model]], lty = 2) +
      geom_path() +
      facet_grid(cm ~ .) +
      scale_x_continuous("Fatigue ->") +
      scale_y_continuous("HbA1c") +
      theme(
        axis.title.x = element_text(size = 8)
        , axis.text.x = element_text(size = 7)
        , axis.title.y = element_blank()
        , axis.text.y = element_text(size = 7)
        , strip.text.y = element_blank()
      )
    , nomogram_data |>
      filter(type == "shap") |>
      ggplot(aes(value, hba1c_value)) +
      geom_vline(xintercept = 0, lty = 2) +
      geom_path(aes(color = metric), show.legend = FALSE) +
      facet_grid(cm ~ .) +
      scale_x_continuous("Impact on fatigue ->") +
      scale_color_discrete("") +
      theme(
        axis.title.x = element_text(size = 8)
        , axis.text.x = element_text(size = 7)
        , axis.title.y = element_blank()
        , axis.text.y = element_blank()
        , strip.text.y = element_blank()
      )
    , nrow = 1, ncol = 3
    , widths = c(1.33071, 1.5, 1.5)
  )
```

```{r Draw workflow for the model, include=FALSE}
workflow <-
  data.frame(
    x = c(0, 1), y = c(0, 2), j = c(NA, NA), type = c(NA, NA), label = c("", "")
  ) |>
  rbind(data.frame(x = 0.5, y = 2, j = 1.84, type = 1, label = "Start")) |>
  rbind(
    data.frame(
      x = 0.5, y = 1.7, j = 1.4, type = 2
      , label = "Type 2 diabetes,\nOHA last 3 months,\nand fatigue?"
    )
  ) |>
  rbind(data.frame(x = 0, y = 1.7, j = NA, type = 3, label = "No")) |>
  rbind(data.frame(x = 0.6, y = 1.5, j = NA, type = 3, label = "Yes")) |>
  rbind(
    data.frame(
      x = 0.5, y = 1.3, j = 1.05, type = 2
      , label = "Medical records\naccessible?"
    )
  ) |>
  rbind(data.frame(x = 0, y = 1.3, j = NA, type = 3, label = "No")) |>
  rbind(data.frame(x = 0.6, y = 1.15, j = NA, type = 3, label = "Yes")) |>
  rbind(
    data.frame(
      x = 0.5, y = 0.9, j = 0.66, type = 1
      , label = "Use\nweb application\nor nomogram"
    )
  ) |>
  rbind(
    data.frame(x = 0.5, y = 0.6, j = 0.4, type = 2, label = "Fatigue detected?")
  ) |>
  rbind(data.frame(x = 0, y = 0.6, j = NA, type = 3, label = "No")) |>
  rbind(data.frame(x = 0.6, y = 0.5, j = NA, type = 3, label = "Yes")) |>
  rbind(
    data.frame(
      x = 0.5, y = 0.3, j = 0.06, type = 2
      , label = "HbA1c impact >0\nand the highest?"
    )
  ) |>
  rbind(data.frame(x = 0, y = 0.3, j = NA, type = 3, label = "No")) |>
  rbind(data.frame(x = 0.6, y = 0.15, j = NA, type = 3, label = "Yes")) |>
  rbind(data.frame(x = 0.5, y = 0, j = NA, type = 1, label = "End")) |>
  mutate(i = x - 0.425) |>
  ggplot(aes(x, y)) +
  geom_edges(
    aes(xend = ifelse(type == 2, i, NA), yend = y)
    , arrow = arrow(length = unit(0.15, "line"), type = "closed")
    , na.rm = TRUE
  ) +
  geom_edges(
    aes(xend = x, yend = j)
    , arrow = arrow(length = unit(0.15, "line"), type = "closed")
    , na.rm = TRUE
  ) +
  geom_label(
    aes(label = ifelse(type == 1, label, NA), fill = factor(type))
    , size = 2, hjust = 0.5, vjust = 0.5, na.rm = TRUE, show.legend = FALSE
  ) +
  geom_label(
    aes(label = ifelse(type == 2, label, NA), fill = factor(type))
    , size = 1.75, hjust = 0.5, vjust = 0.5, na.rm = TRUE, show.legend = FALSE
  ) +
  geom_text(
    aes(label = ifelse(type == 3, label, NA))
    , size = 1.5, hjust = 0.5, vjust = 0.5, na.rm = TRUE
  ) +
  theme_blank()
```

```{r figure-12, echo=FALSE, fig.height=3, fig.width=1.1811, include=FALSE}
workflow
```

```{r Design web app interface, include=FALSE}
web_app_interface <-
  ggarrange(
    data.frame(x = c(0, 1), y = c(0, 0.6), label = c("", "")) |>
      rbind(data.frame(x = 0.05, y = 0.5, label = "Summary:")) |>
      rbind(
        data.frame(x = 0.05, y = 0.4, label = "Is fatigue detected? Yes")
      ) |>
      rbind(
        data.frame(
          x = 0.05, y = 0.3
          , label = "Fatigue probability: 43.9% (threshold=40%)"
        )
      ) |>
      rbind(
        data.frame(
          x = 0.05, y = 0.1
          , label = "Is fatigue related to poor HbA1c?"
        )
      ) |>
      rbind(
        data.frame(
          x = 0.05, y = 0
          , label =
            paste0(
              "Yes, HbA1c (=8) increases fatigue probability "
              , "the highest by 36.33%."
            )
        )
      ) |>
      ggplot(aes(x, y)) +
      geom_text(aes(label = label), size = 2.5, hjust = 0, vjust = 0) +
      theme_blank()
    , predict_with_shap_waterfall(
        comorbidity = 0 # 0 or 1
        , hba1c = 8 # 5.9 to 10.1
        , dm_treatment = 0 # 0 or 1
      )
    , nrow = 2, ncol = 1
    , heights = c(1.25, 1.75)
  )
```

```{r figure-13, echo=FALSE, fig.height=3, fig.width=4.33071, include=FALSE}
web_app_interface
```

```{r Save input for deploying models, eval=FALSE, include=FALSE}
saveRDS(depmod_data, "data/depmod_data.rds")
saveRDS(best_model_prob, "data/best_model_prob.rds")
saveRDS(dep_formatted_data, "data/dep_formatted_data.rds")
```

```{r figure-14, echo=FALSE, fig.height=5, fig.width=5.51181}
nomogram
```

```{r Combine plots for model usage, include=FALSE}
model_usage_plots <-
  ggarrange(
    ggarrange(
      workflow
      , web_app_interface
      , nrow = 1, ncol = 2
      , widths = c(1.1811, 4.33071)
      , labels = LETTERS[1:2]
    )
    , nomogram
    , nrow = 2, ncol = 1
    , heights = c(3, 5)
    , labels = c("", LETTERS[3])
  )
```

```{r figure-15, echo=FALSE, fig.height=8, fig.width=5.51181}
model_usage_plots
```

```{r Fig. 3, eval=FALSE, fig.height=8, fig.width=5.51181, include=FALSE}
model_usage_plots
ggsave("doc/figure3.eps", height = 8, width = 5.51181, units = "in")
```

# Session information

```{r session-info, echo=TRUE}
sessionInfo()
```



















